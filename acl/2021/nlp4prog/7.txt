Reading StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation | Gabriel Orlanski | answering a programming question with only its title is difficult as salient contextual information is left out. to address this , we present a corpus of over 40 , 000 stackoverflow question texts to be used in conjunction with the corresponding intents from the conala dataset \( yin et al. , 2018 \) . using both the intent and the question body , we use bart to establish a baseline bleu score of 34.35 for this new task. we then find further improvements of 2.8% by combining the mined conala data with the labeled data to achieve a 35.32 bleu score. we then evaluate the prior state-of-the-art conala models with this additional data. we find that our proposed method of using the body and mined data beats that of the previous state-of-the-art by a 71.96% bleu score. finally , we perform ablations that prove that bart is an unsupervised multimodal learner and examine its extractive behavior.
