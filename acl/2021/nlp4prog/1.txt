ConTest: A Unit Test Completion Benchmark featuring Context | Johannes Villmow | we introduce contest , a benchmark for nlp-based unit test completion , the task of predicting a testâ€™s assert statements given its setup and focal method , i.e. the method to be tested. contest is large-scale \( with 365k datapoints \) . besides the test code and tested code , it also features context code called by either. we found context to be crucial for accurately predicting assertions. we also introduce baselines based on transformer encoder-decoders , and study the effects of including syntactic information and context. overall , our models achieve a bleu score of 38.2 , while only generating unparsable code in 1.92% of cases.
