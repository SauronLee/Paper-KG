Edinburgh’s End-to-End Multilingual Speech Translation System for IWSLT 2021 | Biao Zhang | this paper describes edinburgh’s submissions to the iwslt2021 multilingual speech translation \( st \) task. we aim at improving multilingual translation and zero-shot performance in the constrained setting \( without using any extra training data \) through methods that encourage transfer learning and larger capacity modeling with advanced neural components. we build our end-to-end multilingual st model based on transformer , integrating techniques including adaptive speech feature selection , language-specific modeling , multi-task learning , deep and big transformer , sparsified linear attention and root mean square layer normalization. we adopt data augmentation using machine translation models for st which converts the zero-shot problem into a zero-resource one. experimental results show that these methods deliver substantial improvements , surpassing the official baseline by > 15 average bleu and outperforming our cascading system by > 2 average bleu. our final submission achieves competitive performance \( runner up \) .
