Inverted Projection for Robust Speech Translation | Dirk Padfield | traditional translation systems trained on written documents perform well for text-based translation but not as well for speech-based applications. we aim to adapt translation models to speech by introducing actual lexical errors from asr and segmentation errors from automatic punctuation into our translation training data. we introduce an inverted projection approach that projects automatically detected system segments onto human transcripts and then re-segments the gold translations to align with the projected human transcripts. we demonstrate that this overcomes the train-test mismatch present in other training approaches. the new projection approach achieves gains of over 1 bleu point over a baseline that is exposed to the human transcripts and segmentations , and these gains hold for both iwslt data and youtube data.
