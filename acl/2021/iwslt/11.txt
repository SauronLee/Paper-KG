VUS at IWSLT 2021: A Finetuned Pipeline for Offline Speech Translation | Yong Rae Jo | in this technical report , we describe the fine-tuned asr-mt pipeline used for the iwslt shared task. we remove less useful speech samples by checking wer with an asr model , and further train a wav2vec and transformers-based asr module based on the filtered data. in addition , we cleanse the errata that can interfere with the machine translation process and use it for transformer-based mt module training. finally , in the actual inference phase , we use a sentence boundary detection model trained with constrained data to properly merge fragment asr outputs into full sentences. the merged sentences are post-processed using part of speech. the final result is yielded by the trained mt module. the performance using the dev set displays bleu 20.37 , and this model records the performance of bleu 20.9 with the test set.
