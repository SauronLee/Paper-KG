THE IWSLT 2021 BUT SPEECH TRANSLATION SYSTEMS | hari Krishna Vydana | the paper describes butâ€™s english to german offline speech translation \( st \) systems developed for iwslt2021. they are based on jointly trained automatic speech recognition-machine translation models. their performances is evaluated on mustc-common test set. in this work , we study their efficiency from the perspective of having a large amount of separate asr training data and mt training data , and a smaller amount of speech-translation training data. large amounts of asr and mt training data are utilized for pre-training the asr and mt models. speech-translation data is used to jointly optimize asr-mt models by defining an end-to-end differentiable path from speech to translations. for this purpose , we use the internal continuous representations from the asr-decoder as the input to mt module. we show that speech translation can be further improved by training the asr-decoder jointly with the mt-module using large amount of text-only mt training data. we also show significant improvements by training an asr module capable of generating punctuated text , rather than leaving the punctuation task to the mt module.
