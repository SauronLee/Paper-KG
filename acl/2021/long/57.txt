Increasing Faithfulness in Knowledge-Grounded Dialogue with Controllable Features | Hannah Rashkin | knowledge-grounded dialogue systems are intended to convey information that is based on evidence provided in a given source text. we discuss the challenges of training a generative neural dialogue model for such systems that is controlled to stay faithful to the evidence. existing datasets contain a mix of conversational responses that are faithful to selected evidence as well as more subjective or chit-chat style responses. we propose different evaluation measures to disentangle these different styles of responses by quantifying the informativeness and objectivity. at training time , additional inputs based on these evaluation measures are given to the dialogue model. at generation time , these additional inputs act as stylistic controls that encourage the model to generate responses that are faithful to the provided evidence. we also investigate the usage of additional controls at decoding time using resampling techniques. in addition to automatic metrics , we perform a human evaluation study where raters judge the output of these controlled generation models to be generally more objective and faithful to the evidence compared to baseline dialogue systems.
