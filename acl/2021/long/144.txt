Bird’s Eye: Probing for Linguistic Graph Structures with a Simple Information-Theoretic Approach | Yifan Hou | nlp has a rich history of representing our prior understanding of language in the form of graphs. recent work on analyzing contextualized text representations has focused on hand-designed probe models to understand how and to what extent do these representations encode a particular linguistic phenomenon. however , due to the inter-dependence of various phenomena and randomness of training probe models , detecting how these representations encode the rich information in these linguistic graphs remains a challenging problem. in this paper , we propose a new information-theoretic probe , bird’s eye , which is a fairly simple probe method for detecting if and how these representations encode the information in these linguistic graphs. instead of using model performance , our probe takes an information-theoretic view of probing and estimates the mutual information between the linguistic graph embedded in a continuous space and the contextualized word representations. furthermore , we also propose an approach to use our probe to investigate localized linguistic information in the linguistic graphs using perturbation analysis. we call this probing setup worm’s eye. using these probes , we analyze the bert models on its ability to encode a syntactic and a semantic graph structure , and find that these models encode to some degree both syntactic as well as semantic information; albeit syntactic information to a greater extent.
