LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking | Hang Jiang | entity linking \( el \) is the task of disambiguating mentions appearing in text by linking them to entities in a knowledge graph , a crucial task for text understanding , question answering or conversational systems. in the special case of short-text el , which poses additional challenges due to limited context , prior approaches have reached good performance by employing heuristics-based methods or purely neural approaches. here , we take a different , neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. even though constrained to use rules , we show that we reach competitive or better performance with sota black-box neural approaches. furthermore , our framework has the benefits of extensibility and transferability. we show that we can easily blend existing rule templates given by a human expert , with multiple types of features \( priors , bert encodings , box embeddings , etc \) , and even with scores resulting from previous el methods , thus improving on such methods. as an example of improvement , on the lc-quad-1.0 dataset , we show more than 3% increase in f1 score relative to previous sota. finally , we show that the inductive bias offered by using logic results in a set of learned rules that transfers from one dataset to another , sometimes without finetuning , while still having high accuracy.
