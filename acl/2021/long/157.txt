Edited Media Understanding Frames: Reasoning About the Intent and Implications of Visual Misinformation | Jeff Da | understanding manipulated media , from automatically generated ‘deepfakes’ to manually edited ones , raises novel research challenges. because the vast majority of edited or manipulated images are benign , such as photoshopped images for visual enhancements , the key challenge is to understand the complex layers of underlying intents of media edits and their implications with respect to disinformation. in this paper , we study edited media frames , a new formalism to understand visual media manipulation as structured annotations with respect to the intents , emotional reactions , attacks on individuals , and the overall implications of disinformation. we introduce a dataset for our task , emu , with 56k question-answer pairs written in rich natural language. we evaluate a wide variety of vision-and-language models for our task , and introduce a new model pelican , which builds upon recent progress in pretrained multimodal representations. our model obtains promising results on our dataset , with humans rating its answers as accurate 48.2% of the time. at the same time , there is still much work to be done – and we provide analysis that highlights areas for further progress.
