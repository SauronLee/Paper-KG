Multi-perspective Coherent Reasoning for Helpfulness Prediction of Multimodal Reviews | Junhao Liu | as more and more product reviews are posted in both text and images , multimodal review analysis \( mra \) becomes an attractive research topic. among the existing review analysis tasks , helpfulness prediction on review text has become predominant due to its importance for e-commerce platforms and online shops , i.e. helping customers quickly acquire useful product information. this paper proposes a new task multimodal review helpfulness prediction \( mrhp \) aiming to analyze the review helpfulness from text and visual modalities. meanwhile , a novel multi-perspective coherent reasoning method \( mcr \) is proposed to solve the mrhp task , which conducts joint reasoning over texts and images from both the product and the review , and aggregates the signals to predict the review helpfulness. concretely , we first propose a product-review coherent reasoning module to measure the intra- and inter-modal coherence between the target product and the review. in addition , we also devise an intra-review coherent reasoning module to identify the coherence between the text content and images of the review , which is a piece of strong evidence for review helpfulness prediction. to evaluate the effectiveness of mcr , we present two newly collected multimodal review datasets as benchmark evaluation resources for the mrhp task. experimental results show that our mcr method can lead to a performance increase of up to 8.5% as compared to the best performing text-only model. the source code and datasets can be obtained from https://github.com/jhliu17/mcr.
