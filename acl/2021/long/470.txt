RepSum: Unsupervised Dialogue Summarization based on Replacement Strategy | Xiyan Fu | in the field of dialogue summarization , due to the lack of training data , it is often difficult for supervised summary generation methods to learn vital information from dialogue context with limited data. several attempts on unsupervised summarization for text by leveraging semantic information solely or auto-encoder strategy \( i.e. , sentence compression \) , it however cannot be adapted to the dialogue scene due to the limited words in utterances and huge gap between the dialogue and its summary. in this study , we propose a novel unsupervised strategy to address this challenge , which roots from the hypothetical foundation that a superior summary approximates a replacement of the original dialogue , and they are roughly equivalent for auxiliary \( self-supervised \) tasks , e.g. , dialogue generation. the proposed strategy repsum is applied to generate both extractive and abstractive summary with the guidance of the followed nË†th utterance generation and classification tasks. extensive experiments on various datasets demonstrate the superiority of the proposed model compared with the state-of-the-art methods.
