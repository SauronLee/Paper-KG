BanditMTL: Bandit-based Multi-task Learning for Text Classification | Yuren Mao | task variance regularization , which can be used to improve the generalization of multi-task learning \( mtl \) models , remains unexplored in multi-task text classification. accordingly , to fill this gap , this paper investigates how the task might be effectively regularized , and consequently proposes a multi-task learning method based on adversarial multi-armed bandit. the proposed method , named banditmtl , regularizes the task variance by means of a mirror gradient ascent-descent algorithm. adopting banditmtl in the multi-task text classification context is found to achieve state-of-the-art performance. the results of extensive experiments back up our theoretical analysis and validate the superiority of our proposals.
