Semi-Supervised Text Classification with Balanced Deep Representation Distributions | Changchun Li | semi-supervised text classification \( sstc \) mainly works under the spirit of self-training. they initialize the deep classifier by training over labeled texts; and then alternatively predict unlabeled texts as their pseudo-labels and train the deep classifier over the mixture of labeled and pseudo-labeled texts. naturally , their performance is largely affected by the accuracy of pseudo-labels for unlabeled texts. unfortunately , they often suffer from low accuracy because of the margin bias problem caused by the large difference between representation distributions of labels in sstc. to alleviate this problem , we apply the angular margin loss , and perform gaussian linear transformation to achieve balanced label angle variances , i.e. , the variance of label angles of texts within the same label. more accuracy of predicted pseudo-labels can be achieved by constraining all label angle variances balanced , where they are estimated over both labeled and pseudo-labeled texts during self-training loops. with this insight , we propose a novel sstc method , namely semi-supervised text classification with balanced deep representation distributions \( s2tc-bdd \) . to evaluate s2tc-bdd , we compare it against the state-of-the-art sstc methods. empirical results demonstrate the effectiveness of s2tc-bdd , especially when the labeled texts are scarce.
