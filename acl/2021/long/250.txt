Can Generative Pre-trained Language Models Serve As Knowledge Bases for Closed-book QA? | Cunxiang Wang | recent work has investigated the interesting question using pre-trained language models \( plms \) as knowledge bases for answering open questions. however , existing work is limited in using small benchmarks with high test-train overlaps. we construct a new dataset of closed-book qa using squad , and investigate the performance of bart. experiments show that it is challenging for bart to remember training facts in high precision , and also challenging to answer closed-book questions even if relevant knowledge is retained. some promising directions are found , including decoupling the knowledge memorizing process and the qa finetune process , forcing the model to recall relevant knowledge when question answering.
