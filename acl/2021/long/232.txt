PLOME: Pre-training with Misspelled Knowledge for Chinese Spelling Correction | Shulin Liu | chinese spelling correction \( csc \) is a task to detect and correct spelling errors in texts. csc is essentially a linguistic problem , thus the ability of language understanding is crucial to this task. in this paper , we propose a pre-trained masked language model with misspelled knowledge \( plome \) for csc , which jointly learns how to understand language and correct spelling errors. to this end , plome masks the chosen tokens with similar characters according to a confusion set rather than the fixed token “[mask]” as in bert. besides character prediction , plome also introduces pronunciation prediction to learn the misspelled knowledge on phonic level. moreover , phonological and visual similarity knowledge is important to this task. plome utilizes gru networks to model such knowledge based on characters’ phonics and strokes. experiments are conducted on widely used benchmarks. our method achieves superior performance against state-of-the-art approaches by a remarkable margin. we release the source code and pre-trained model for further use by the community \( https://github.com/liushulinle/plome \) .
