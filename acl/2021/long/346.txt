Claim Matching Beyond English to Scale Global Fact-Checking | Ashkan Kazemi | manual fact-checking does not scale well to serve the needs of the internet. this issue is further compounded in non-english contexts. in this paper , we discuss claim matching as a possible solution to scale fact-checking. we define claim matching as the task of identifying pairs of textual messages containing claims that can be served with one fact-check. we construct a novel dataset of whatsapp tipline and public group messages alongside fact-checked claims that are first annotated for containing “claim-like statements” and then matched with potentially similar items and annotated for claim matching. our dataset contains content in high-resource \( english , hindi \) and lower-resource \( bengali , malayalam , tamil \) languages. we train our own embedding model using knowledge distillation and a high-quality “teacher” model in order to address the imbalance in embedding quality between the low- and high-resource languages in our dataset. we provide evaluations on the performance of our solution and compare with baselines and existing state-of-the-art multilingual embedding models , namely laser and labse. we demonstrate that our performance exceeds laser and labse in all settings. we release our annotated datasets , codebooks , and trained embedding model to allow for further research.
