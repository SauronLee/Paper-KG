A Targeted Assessment of Incremental Processing in Neural Language Models and Humans | Ethan Wilcox | we present a targeted , scaled-up comparison of incremental processing in humans and neural language models by collecting by-word reaction time data for sixteen different syntactic test suites across a range of structural phenomena. human reaction time data comes from a novel online experimental paradigm called the interpolated maze task. we compare human reaction times to by-word probabilities for four contemporary language models , with different architectures and trained on a range of data set sizes. we find that across many phenomena , both humans and language models show increased processing difficulty in ungrammatical sentence regions with human and model ‘accuracy’ scores a la marvin and linzen \( 2018 \) about equal. however , although language model outputs match humans in direction , we show that models systematically under-predict the difference in magnitude of incremental processing difficulty between grammatical and ungrammatical sentences. specifically , when models encounter syntactic violations they fail to accurately predict the longer reading times observed in the human data. these results call into question whether contemporary language models are approaching human-like performance for sensitivity to syntactic violations.
