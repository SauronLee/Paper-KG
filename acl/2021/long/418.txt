On Sample Based Explanation Methods for NLP: Faithfulness, Efficiency and Semantic Evaluation | Wei Zhang | in the recent advances of natural language processing , the scale of the state-of-the-art models and datasets is usually extensive , which challenges the application of sample-based explanation methods in many aspects , such as explanation interpretability , efficiency , and faithfulness. in this work , for the first time , we can improve the interpretability of explanations by allowing arbitrary text sequences as the explanation unit. on top of this , we implement a hessian-free method with a model faithfulness guarantee. finally , to compare our method with the others , we propose a semantic-based evaluation metric that can better align with humans’ judgment of explanations than the widely adopted diagnostic or re-training measures. the empirical results on multiple real data sets demonstrate the proposed method’s superior performance to popular explanation techniques such as influence function or tracin on semantic evaluation.
