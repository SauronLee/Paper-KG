HERALD: An Annotation Efficient Method to Detect User Disengagement in Social Conversations | Weixin Liang | open-domain dialog systems have a user-centric goal: to provide humans with an engaging conversation experience. user engagement is one of the most important metrics for evaluating open-domain dialog systems , and could also be used as real-time feedback to benefit dialog policy learning. existing work on detecting user disengagement typically requires hand-labeling many dialog samples. we propose herald , an efficient annotation framework that reframes the training data annotation process as a denoising problem. specifically , instead of manually labeling training samples , we first use a set of labeling heuristics to label training samples automatically. we then denoise the weakly labeled data using the shapley algorithm. finally , we use the denoised data to train a user engagement detector. our experiments show that herald improves annotation efficiency significantly and achieves 86% user disengagement detection accuracy in two dialog corpora.
