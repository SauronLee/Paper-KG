HateCheck: Functional Tests for Hate Speech Detection Models | Paul Röttger | detecting online hate is a difficult task that even state-of-the-art models struggle with. typically , hate speech detection models are evaluated by measuring their performance on held-out test data using metrics such as accuracy and f1 score. however , this approach makes it difficult to identify specific model weak points. it also risks overestimating generalisable model performance due to increasingly well-evidenced systematic gaps and biases in hate speech datasets. to enable more targeted diagnostic insights , we introduce hatecheck , a suite of functional tests for hate speech detection models. we specify 29 model functionalities motivated by a review of previous research and a series of interviews with civil society stakeholders. we craft test cases for each functionality and validate their quality through a structured annotation process. to illustrate hatecheck’s utility , we test near-state-of-the-art transformer models as well as two popular commercial models , revealing critical model weaknesses.
