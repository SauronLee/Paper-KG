Improving the Faithfulness of Attention-based Explanations with Task-specific Information for Text Classification | George Chrysostomou | neural network architectures in natural language processing often use attention mechanisms to produce probability distributions over input token representations. attention has empirically been demonstrated to improve performance in various tasks , while its weights have been extensively used as explanations for model predictions. recent studies \( jain and wallace , 2019; serrano and smith , 2019; wiegreffe and pinter , 2019 \) have showed that it cannot generally be considered as a faithful explanation \( jacovi and goldberg , 2020 \) across encoders and tasks. in this paper , we seek to improve the faithfulness of attention-based explanations for text classification. we achieve this by proposing a new family of task-scaling \( tasc \) mechanisms that learn task-specific non-contextualised information to scale the original attention weights. evaluation tests for explanation faithfulness , show that the three proposed variants of tasc improve attention-based explanations across two attention mechanisms , five encoders and five text classification datasets without sacrificing predictive performance. finally , we demonstrate that tasc consistently provides more faithful attention-based explanations compared to three widely-used interpretability techniques.
