Robustifying Multi-hop QA through Pseudo-Evidentiality Training | Kyungjae Lee | this paper studies the bias problem of multi-hop question answering models , of answering correctly without correct reasoning. one way to robustify these models is by supervising to not only answer right , but also with right reasoning chains. an existing direction is to annotate reasoning chains to train models , requiring expensive additional annotations. in contrast , we propose a new approach to learn evidentiality , deciding whether the answer prediction is supported by correct evidences , without such annotations. instead , we compare counterfactual changes in answer confidence with and without evidence sentences , to generate “pseudo-evidentiality” annotations. we validate our proposed model on an original set and challenge set in hotpotqa , showing that our method is accurate and robust in multi-hop reasoning.
