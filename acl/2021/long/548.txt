TIMEDIAL: Temporal Commonsense Reasoning in Dialog | Lianhui Qin | everyday conversations require understanding everyday events , which in turn , requires understanding temporal commonsense concepts interwoven with those events. despite recent progress with massive pre-trained language models \( lms \) such as t5 and gpt-3 , their capability of temporal reasoning in dialogs remains largely under-explored. in this paper , we present the first study to investigate pre-trained lms for their temporal reasoning capabilities in dialogs by introducing a new task and a crowd-sourced english challenge set , timedial. we formulate timedial as a multiple choice cloze task with over 1.1k carefully curated dialogs. empirical results demonstrate that even the best performing models struggle on this task compared to humans , with 23 absolute points of gap in accuracy. furthermore , our analysis reveals that the models fail to reason about dialog context correctly; instead , they rely on shallow cues based on existing temporal patterns in context , motivating future research for modeling temporal concepts in text and robust contextual reasoning about them. the dataset is publicly available at https://github.com/google-research-datasets/timedial.
