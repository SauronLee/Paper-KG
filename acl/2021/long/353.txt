One2Set: Generating Diverse Keyphrases as a Set | Jiacheng Ye | recently , the sequence-to-sequence models have made remarkable progress on the task of keyphrase generation \( kg \) by concatenating multiple keyphrases in a predefined order as a target sequence during training. however , the keyphrases are inherently an unordered set rather than an ordered sequence. imposing a predefined order will introduce wrong bias during training , which can highly penalize shifts in the order between keyphrases. in this work , we propose a new training paradigm one2set without predefining an order to concatenate the keyphrases. to fit this paradigm , we propose a novel model that utilizes a fixed set of learned control codes as conditions to generate a set of keyphrases in parallel. to solve the problem that there is no correspondence between each prediction and target during training , we propose a k-step label assignment mechanism via bipartite matching , which greatly increases the diversity and reduces the repetition rate of generated keyphrases. the experimental results on multiple benchmarks demonstrate that our approach significantly outperforms the state-of-the-art methods.
