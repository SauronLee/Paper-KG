The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting User Questions About Human or Non-Human Identity | David Gros | humans are increasingly interacting with machines through language , sometimes in contexts where the user may not know they are talking to a machine \( like over the phone or a text chatbot \) . we aim to understand how system designers and researchers might allow their systems to confirm its non-human identity. we collect over 2 , 500 phrasings related to the intent of “are you a robot \? ”. this is paired with over 2 , 500 adversarially selected utterances where only confirming the system is non-human would be insufficient or disfluent. we compare classifiers to recognize the intent and discuss the precision/recall and model complexity tradeoffs. such classifiers could be integrated into dialog systems to avoid undesired deception. we then explore how both a generative research model \( blender \) as well as two deployed systems \( amazon alexa , google assistant \) handle this intent , finding that systems often fail to confirm their non-human identity. finally , we try to understand what a good response to the intent would be , and conduct a user study to compare the important aspects when responding to this intent.
