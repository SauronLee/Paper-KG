End-to-End Training of Neural Retrievers for Open-Domain Question Answering | Devendra Sachan | recent work on training neural retrievers for open-domain question answering \( openqa \) has employed both supervised and unsupervised approaches. however , it remains unclear how unsupervised and supervised methods can be used most effectively for neural retrievers. in this work , we systematically study retriever pre-training. we first propose an approach of unsupervised pre-training with the inverse cloze task and masked salient spans , followed by supervised finetuning using question-context pairs. this approach leads to absolute gains of 2+ points over the previous best result in the top-20 retrieval accuracy on natural questions and triviaqa datasets. we next explore two approaches for end-to-end training of the reader and retriever components in openqa models , which differ in the manner the reader ingests the retrieved documents. our experiments demonstrate the effectiveness of these approaches as we obtain state-of-the-art results. on the natural questions dataset , we obtain a top-20 retrieval accuracy of 84% , an improvement of 5 points over the recent dpr model. we also achieve good results on answer extraction , outperforming recent models like realm and rag by 3+ points.
