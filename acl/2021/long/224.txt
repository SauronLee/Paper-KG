Unsupervised Neural Machine Translation for Low-Resource Domains via Meta-Learning | Cheonbok Park | unsupervised machine translation , which utilizes unpaired monolingual corpora as training data , has achieved comparable performance against supervised machine translation. however , it still suffers from data-scarce domains. to address this issue , this paper presents a novel meta-learning algorithm for unsupervised neural machine translation \( unmt \) that trains the model to adapt to another domain by utilizing only a small amount of training data. we assume that domain-general knowledge is a significant factor in handling data-scarce domains. hence , we extend the meta-learning algorithm , which utilizes knowledge learned from high-resource domains , to boost the performance of low-resource unmt. our model surpasses a transfer learning-based approach by up to 2-3 bleu scores. extensive experimental results show that our proposed algorithm is pertinent for fast adaptation and consistently outperforms other baselines.
