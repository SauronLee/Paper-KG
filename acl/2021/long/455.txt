Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks | Jinghui Qin | previous math word problem solvers following the encoder-decoder paradigm fail to explicitly incorporate essential math symbolic constraints , leading to unexplainable and unreasonable predictions. herein , we propose neural-symbolic solver \( ns-solver \) to explicitly and seamlessly incorporate different levels of symbolic constraints by auxiliary tasks. our ns-solver consists of a problem reader to encode problems , a programmer to generate symbolic equations , and a symbolic executor to obtain answers. along with target expression supervision , our solver is also optimized via 4 new auxiliary objectives to enforce different symbolic reasoning: a \) self-supervised number prediction task predicting both number quantity and number locations; b \) commonsense constant prediction task predicting what prior knowledge \( e.g. how many legs a chicken has \) is required; c \) program consistency checker computing the semantic loss between predicted equation and target equation to ensure reasonable equation mapping; d \) duality exploiting task exploiting the quasi-duality between symbolic equation generation and problemâ€™s part-of-speech generation to enhance the understanding ability of a solver. besides , to provide a more realistic and challenging benchmark for developing a universal and scalable solver , we also construct a new largescale mwp benchmark cm17k consisting of 4 kinds of mwps \( arithmetic , one-unknown linear , one-unknown non-linear , equation set \) with more than 17k samples. extensive experiments on math23k and our cm17k demonstrate the superiority of our ns-solver compared to state-of-the-art methods.
