Understanding the Properties of Minimum Bayes Risk Decoding in Neural Machine Translation | Mathias Müller | neural machine translation \( nmt \) currently exhibits biases such as producing translations that are too short and overgenerating frequent words , and shows poor robustness to copy noise in training data or domain shift. recent work has tied these shortcomings to beam search – the de facto standard inference algorithm in nmt – and eikema & aziz \( 2020 \) propose to use minimum bayes risk \( mbr \) decoding on unbiased samples instead. in this paper , we empirically investigate the properties of mbr decoding on a number of previously reported biases and failure cases of beam search. we find that mbr still exhibits a length and token frequency bias , owing to the mt metrics used as utility functions , but that mbr also increases robustness against copy noise in the training data and domain shift.
