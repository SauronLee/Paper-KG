Language Model Augmented Relevance Score | Ruibo Liu | although automated metrics are commonly used to evaluate nlg systems , they often correlate poorly with human judgements. newer metrics such as bertscore have addressed many weaknesses in prior metrics such as bleu and rouge , which rely on n-gram matching. these newer methods , however , are still limited in that they do not consider the generation context , so they cannot properly reward generated text that is correct but deviates from the given reference. in this paper , we propose language model augmented relevance score \( mars \) , a new context-aware metric for nlg evaluation. mars leverages off-the-shelf language models , guided by reinforcement learning , to create augmented references that consider both the generation context and available human references , which are then used as additional references to score generated text. compared with seven existing metrics in three common nlg tasks , mars not only achieves higher correlation with human reference judgements , but also differentiates well-formed candidates from adversarial samples to a larger degree.
