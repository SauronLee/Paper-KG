Rational LAMOL: A Rationale-based Lifelong Learning Framework | Kasidis Kanwatchara | lifelong learning \( ll \) aims to train a neural network on a stream of tasks while retaining knowledge from previous tasks. however , many prior attempts in nlp still suffer from the catastrophic forgetting issue , where the model completely forgets what it just learned in the previous tasks. in this paper , we introduce rational lamol , a novel end-to-end ll framework for language models. in order to alleviate catastrophic forgetting , rational lamol enhances lamol , a recent ll model , by applying critical freezing guided by human rationales. when the human rationales are not available , we propose exploiting unsupervised generated rationales as substitutions. in the experiment , we tested rational lamol on permutations of three datasets from the eraser benchmark. the results show that our proposed framework outperformed vanilla lamol on most permutations. furthermore , unsupervised rationale generation was able to consistently improve the overall ll performance from the baseline without relying on human-annotated rationales.
