Hierarchical Context-aware Network for Dense Video Event Captioning | Lei Ji | dense video event captioning aims to generate a sequence of descriptive captions for each event in a long untrimmed video. video-level context provides important information and facilities the model to generate consistent and less redundant captions between events. in this paper , we introduce a novel hierarchical context-aware network for dense video event captioning \( hcn \) to capture context from various aspects. in detail , the model leverages local and global context with different mechanisms to jointly learn to generate coherent captions. the local context module performs full interaction between neighbor frames and the global context module selectively attends to previous or future events. according to our extensive experiment on both youcook2 and activitynet captioning datasets , the video-level hcn model outperforms the event-level context-agnostic model by a large margin. the code is available at https://github.com/kirkguo/hcn.
