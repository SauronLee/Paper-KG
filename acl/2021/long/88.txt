Multi-Task Retrieval for Knowledge-Intensive Tasks | Jean Maillard | retrieving relevant contexts from a large corpus is a crucial step for tasks such as open-domain question answering and fact checking. although neural retrieval outperforms traditional methods like tf-idf and bm25 , its performance degrades considerably when applied to out-of-domain data. driven by the question of whether a neural retrieval model can be _universal_ and perform robustly on a wide variety of problems , we propose a multi-task trained model. our approach not only outperforms previous methods in the few-shot setting , but also rivals specialised neural retrievers , even when in-domain training data is abundant. with the help of our retriever , we improve existing models for downstream tasks and closely match or improve the state of the art on multiple benchmarks.
