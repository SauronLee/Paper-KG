Integrated Directional Gradients: Feature Interaction Attribution for Neural NLP Models | Sandipan Sikdar | in this paper , we introduce integrated directional gradients \( idg \) , a method for attributing importance scores to groups of features , indicating their relevance to the output of a neural network model for a given input. the success of deep neural networks has been attributed to their ability to capture higher level feature interactions. hence , in the last few years capturing the importance of these feature interactions has received increased prominence in ml interpretability literature. in this paper , we formally define the feature group attribution problem and outline a set of axioms that any intuitive feature group attribution method should satisfy. earlier , cooperative game theory inspired axiomatic methods only borrowed axioms from solution concepts \( such as shapley value \) for individual feature attributions and introduced their own extensions to model interactions. in contrast , our formulation is inspired by axioms satisfied by characteristic functions as well as solution concepts in cooperative game theory literature. we believe that characteristic functions are much better suited to model importance of groups compared to just solution concepts. we demonstrate that our proposed method , idg , satisfies all the axioms. using idg we analyze two state-of-the-art text classifiers on three benchmark datasets for sentiment analysis. our experiments show that idg is able to effectively capture semantic interactions in linguistic models via negations and conjunctions.
