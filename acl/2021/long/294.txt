Making Pre-trained Language Models Better Few-shot Learners | Tianyu Gao | the recent gpt-3 model \( brown et al. , 2020 \) achieves remarkable few-shot performance solely by leveraging a natural-language prompt and a few task demonstrations as input context. inspired by their findings , we study few-shot learning in a more practical scenario , where we use smaller language models for which fine-tuning is computationally efficient. we present lm-bff—better few-shot fine-tuning of language models—a suite of simple and complementary techniques for fine-tuning language models on a small number of annotated examples. our approach includes \( 1 \) prompt-based fine-tuning together with a novel pipeline for automating prompt generation; and \( 2 \) a refined strategy for dynamically and selectively incorporating demonstrations into each context. finally , we present a systematic evaluation for analyzing few-shot performance on a range of nlp tasks , including classification and regression. our experiments demonstrate that our methods combine to dramatically outperform standard fine-tuning procedures in this low resource setting , achieving up to 30% absolute improvement , and 11% on average across all tasks. our approach makes minimal assumptions on task resources and domain expertise , and hence constitutes a strong task-agnostic method for few-shot learning.
