Dependency-driven Relation Extraction with Attentive Graph Convolutional Networks | Yuanhe Tian | syntactic information , especially dependency trees , has been widely used by existing studies to improve relation extraction with better semantic guidance for analyzing the context information associated with the given entities. however , most existing studies suffer from the noise in the dependency trees , especially when they are automatically generated , so that intensively leveraging dependency information may introduce confusions to relation classification and necessary pruning is of great importance in this task. in this paper , we propose a dependency-driven approach for relation extraction with attentive graph convolutional networks \( a-gcn \) . in this approach , an attention mechanism upon graph convolutional networks is applied to different contextual words in the dependency tree obtained from an off-the-shelf dependency parser , to distinguish the importance of different word dependencies. consider that dependency types among words also contain important contextual guidance , which is potentially helpful for relation extraction , we also include the type information in a-gcn modeling. experimental results on two english benchmark datasets demonstrate the effectiveness of our a-gcn , which outperforms previous studies and achieves state-of-the-art performance on both datasets.
