Counterfactual Inference for Text Classification Debiasing | Chen Qian | today’s text classifiers inevitably suffer from unintended dataset biases , especially the document-level label bias and word-level keyword bias , which may hurt models’ generalization. many previous studies employed data-level manipulations or model-level balancing mechanisms to recover unbiased distributions and thus prevent models from capturing the two types of biases. unfortunately , they either suffer from the extra cost of data collection/selection/annotation or need an elaborate design of balancing strategies. different from traditional factual inference in which debiasing occurs before or during training , counterfactual inference mitigates the influence brought by unintended confounders after training , which can make unbiased decisions with biased observations. inspired by this , we propose a model-agnostic text classification debiasing framework – corsair , which can effectively avoid employing data manipulations or designing balancing mechanisms. concretely , corsair first trains a base model on a training set directly , allowing the dataset biases ‘poison’ the trained model. in inference , given a factual input document , corsair imagines its two counterfactual counterparts to distill and mitigate the two biases captured by the poisonous model. extensive experiments demonstrate corsair’s effectiveness , generalizability and fairness.
