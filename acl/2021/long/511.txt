Determinantal Beam Search | Clara Meister | beam search is a go-to strategy for decoding neural sequence models. the algorithm can naturally be viewed as a subset optimization problem , albeit one where the corresponding set function does not reflect interactions between candidates. empirically , this leads to sets often exhibiting high overlap , e.g. , strings may differ by only a single word. yet in use-cases that call for multiple solutions , a diverse or representative set is often desired. to address this issue , we propose a reformulation of beam search , which we call determinantal beam search. determinantal beam search has a natural relationship to determinantal point processes \( dpps \) , models over sets that inherently encode intra-set interactions. by posing iterations in beam search as a series of subdeterminant maximization problems , we can turn the algorithm into a diverse subset selection process. in a case study , we use the string subsequence kernel to explicitly encourage n-gram coverage in text generated from a sequence model. we observe that our algorithm offers competitive performance against other diverse set generation strategies in the context of language generation , while providing a more general approach to optimizing for diversity.
