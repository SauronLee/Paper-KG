Regression Bugs Are In Your Model! Measuring, Reducing and Analyzing Regressions In NLP Model Updates | Yuqing Xie | behavior of deep neural networks can be inconsistent between different versions. regressions during model update are a common cause of concern that often over-weigh the benefits in accuracy or efficiency gain. this work focuses on quantifying , reducing and analyzing regression errors in the nlp model updates. using negative flip rate as regression measure , we show that regression has a prevalent presence across tasks in the glue benchmark. we formulate the regression-free model updates into a constrained optimization problem , and further reduce it into a relaxed form which can be approximately optimized through knowledge distillation training method. we empirically analyze how model ensemble reduces regression. finally , we conduct checklist behavioral testing to understand the distribution of regressions across linguistic phenomena , and the efficacy of ensemble and distillation methods.
