A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal Trigger’s Adversarial Attacks | Thai Le | the universal trigger \( unitrigger \) is a recently-proposed powerful adversarial textual attack method. utilizing a learning-based mechanism , unitrigger generates a fixed phrase that , when added to any benign inputs , can drop the prediction accuracy of a textual neural network \( nn \) model to near zero on a target class. to defend against this attack that can cause significant harm , in this paper , we borrow the “honeypot” concept from the cybersecurity community and propose darcy , a honeypot-based defense framework against unitrigger. darcy greedily searches and injects multiple trapdoors into an nn model to “bait and catch” potential attacks. through comprehensive experiments across four public datasets , we show that darcy detects unitrigger’s adversarial attacks with up to 99% tpr and less than 2% fpr in most cases , while maintaining the prediction accuracy \( in f1 \) for clean inputs within a 1% margin. we also demonstrate that darcy with multiple trapdoors is also robust to a diverse set of attack scenarios with attackers’ varying levels of knowledge and skills. we release the source code of darcy at: https://github.com/lethaiq/acl2021-darcy-honeypotdefensenlp.
