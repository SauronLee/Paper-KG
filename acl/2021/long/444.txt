Importance-based Neuron Allocation for Multilingual Neural Machine Translation | Wanying Xie | multilingual neural machine translation with a single model has drawn much attention due to its capability to deal with multiple languages. however , the current multilingual translation paradigm often makes the model tend to preserve the general knowledge , but ignore the language-specific knowledge. some previous works try to solve this problem by adding various kinds of language-specific modules to the model , but they suffer from the parameter explosion problem and require specialized manual design. to solve these problems , we propose to divide the model neurons into general and language-specific parts based on their importance across languages. the general part is responsible for preserving the general knowledge and participating in the translation of all the languages , while the language-specific part is responsible for preserving the language-specific knowledge and participating in the translation of some specific languages. experimental results on several language pairs , covering iwslt and europarl corpus datasets , demonstrate the effectiveness and universality of the proposed method.
