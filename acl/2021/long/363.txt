Benchmarking Scalable Methods for Streaming Cross Document Entity Coreference | Robert L Logan IV | streaming cross document entity coreference \( cdc \) systems disambiguate mentions of named entities in a scalable manner via incremental clustering. unlike other approaches for named entity disambiguation \( e.g. , entity linking \) , streaming cdc allows for the disambiguation of entities that are unknown at inference time. thus , it is well-suited for processing streams of data where new entities are frequently introduced. despite these benefits , this task is currently difficult to study , as existing approaches are either evaluated on datasets that are no longer available , or omit other crucial details needed to ensure fair comparison. in this work , we address this issue by compiling a large benchmark adapted from existing free datasets , and performing a comprehensive evaluation of a number of novel and existing baseline models. we investigate: how to best encode mentions , which clustering algorithms are most effective for grouping mentions , how models transfer to different domains , and how bounding the number of mentions tracked during inference impacts performance. our results show that the relative performance of neural and feature-based mention encoders varies across different domains , and in most cases the best performance is achieved using a combination of both approaches. we also find that performance is minimally impacted by limiting the number of tracked mentions.
