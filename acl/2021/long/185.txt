DynaSent: A Dynamic Benchmark for Sentiment Analysis | Christopher Potts | we introduce dynasent \( ‘dynamic sentiment’ \) , a new english-language benchmark task for ternary \( positive/negative/neutral \) sentiment analysis. dynasent combines naturally occurring sentences with sentences created using the open-source dynabench platform , which facilities human-and-model-in-the-loop dataset creation. dynasent has a total of 121 , 634 sentences , each validated by five crowdworkers , and its development and test splits are designed to produce chance performance for even the best models we have been able to develop; when future models solve this task , we will use them to create dynasent version 2 , continuing the dynamic evolution of this benchmark. here , we report on the dataset creation effort , focusing on the steps we took to increase quality and reduce artifacts. we also present evidence that dynasent’s neutral category is more coherent than the comparable category in other benchmarks , and we motivate training models from scratch for each round over successive fine-tuning.
