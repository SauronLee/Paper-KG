Verb Knowledge Injection for Multilingual Event Processing | Olga Majewska | linguistic probing of pretrained transformer-based language models \( lms \) revealed that they encode a range of syntactic and semantic properties of a language. however , they are still prone to fall back on superficial cues and simple heuristics to solve downstream tasks , rather than leverage deeper linguistic information. in this paper , we target a specific facet of linguistic knowledge , the interplay between verb meaning and argument structure. we investigate whether injecting explicit information on verbsâ€™ semantic-syntactic behaviour improves the performance of pretrained lms in event extraction tasks , where accurate verb processing is paramount. concretely , we impart the verb knowledge from curated lexical resources into dedicated adapter modules \( verb adapters \) , allowing it to complement , in downstream tasks , the language knowledge obtained during lm-pretraining. we first demonstrate that injecting verb knowledge leads to performance gains in english event extraction. we then explore the utility of verb adapters for event extraction in other languages: we investigate 1 \) zero-shot language transfer with multilingual transformers and 2 \) transfer via \( noisy automatic \) translation of english verb-based lexical knowledge. our results show that the benefits of verb knowledge injection indeed extend to other languages , even when relying on noisily translated lexical knowledge.
