Towards Robustness of Text-to-SQL Models against Synonym Substitution | Yujian Gan | recently , there has been significant progress in studying neural networks to translate text descriptions into sql queries. despite achieving good performance on some public benchmarks , existing text-to-sql models typically rely on the lexical matching between words in natural language \( nl \) questions and tokens in table schemas , which may render the models vulnerable to attacks that break the schema linking mechanism. in this work , we investigate the robustness of text-to-sql models to synonym substitution. in particular , we introduce spider-syn , a human-curated dataset based on the spider benchmark for text-to-sql translation. nl questions in spider-syn are modified from spider , by replacing their schema-related words with manually selected synonyms that reflect real-world question paraphrases. we observe that the accuracy dramatically drops by eliminating such explicit correspondence between nl questions and table schemas , even if the synonyms are not adversarially selected to conduct worst-case attacks. finally , we present two categories of approaches to improve the model robustness. the first category of approaches utilizes additional synonym annotations for table schemas by modifying the model input , while the second category is based on adversarial training. we demonstrate that both categories of approaches significantly outperform their counterparts without the defense , and the first category of approaches are more effective.
