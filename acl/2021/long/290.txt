CogAlign: Learning to Align Textual Neural Representations to Cognitive Language Processing Signals | Yuqi Ren | most previous studies integrate cognitive language processing signals \( e.g. , eye-tracking or eeg data \) into neural models of natural language processing \( nlp \) just by directly concatenating word embeddings with cognitive features , ignoring the gap between the two modalities \( i.e. , textual vs. cognitive \) and noise in cognitive features. in this paper , we propose a cogalign approach to these issues , which learns to align textual neural representations to cognitive features. in cogalign , we use a shared encoder equipped with a modality discriminator to alternatively encode textual and cognitive inputs to capture their differences and commonalities. additionally , a text-aware attention mechanism is proposed to detect task-related information and to avoid using noise in cognitive features. experimental results on three nlp tasks , namely named entity recognition , sentiment analysis and relation extraction , show that cogalign achieves significant improvements with multiple cognitive features over state-of-the-art models on public datasets. moreover , our model is able to transfer cognitive information to other datasets that do not have any cognitive processing signals.
