IrEne: Interpretable Energy Prediction for Transformers | Qingqing Cao | existing software-based energy measurements of nlp models are not accurate because they do not consider the complex interactions between energy consumption and model execution. we present irene , an interpretable and extensible energy prediction system that accurately predicts the inference energy consumption of a wide range of transformer-based nlp models. irene constructs a model tree graph that breaks down the nlp model into modules that are further broken down into low-level machine learning \( ml \) primitives. irene predicts the inference energy consumption of the ml primitives as a function of generalizable features and fine-grained runtime resource usage. irene then aggregates these low-level predictions recursively to predict the energy of each module and finally of the entire model. experiments across multiple transformer models show irene predicts inference energy consumption of transformer models with an error of under 7% compared to the ground truth. in contrast , existing energy models see an error of over 50%. we also show how irene can be used to conduct energy bottleneck analysis and to easily evaluate the energy impact of different architectural choices. we release the code and data at https://github.com/stonybrooknlp/irene.
