An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models | Xueqing Liu | the performance of fine-tuning pre-trained language models largely depends on the hyperparameter configuration. in this paper , we investigate the performance of modern hyperparameter optimization methods \( hpo \) on fine-tuning pre-trained language models. first , we study and report three hpo algorithms’ performances on fine-tuning two state-of-the-art language models on the glue dataset. we find that using the same time budget , hpo often fails to outperform grid search due to two reasons: insufficient time budget and overfitting. we propose two general strategies and an experimental procedure to systematically troubleshoot hpo’s failure cases. by applying the procedure , we observe that hpo can succeed with more appropriate settings in the search space and time budget; however , in certain cases overfitting remains. finally , we make suggestions for future work. our implementation can be found in
