How Might We Create Better Benchmarks for Speech Recognition? | Alëna Aksënova | the applications of automatic speech recognition \( asr \) systems are proliferating , in part due to recent significant quality improvements. however , as recent work indicates , even state-of-the-art speech recognition systems – some which deliver impressive benchmark results , struggle to generalize across use cases. we review relevant work , and , hoping to inform future benchmark development , outline a taxonomy of speech recognition use cases , proposed for the next generation of asr benchmarks. we also survey work on metrics , in addition to the de facto standard word error rate \( wer \) metric , and we introduce a versatile framework designed to describe interactions between linguistic variation and asr performance metrics.
