System Description for Transperfect | Wiktor Stribi≈ºew | in this paper , we describe our participation in the 2021 workshop on asian translation \( team id: tpt_wat \) . we submitted results for all six directions of the jpc2 patent task. as a first-time participant in the task , we attempted to identify a single configuration that provided the best overall results across all language pairs. all our submissions were created using single base transformer models , trained on only the task-specific data , using a consistent configuration of hyperparameters. in contrast to the uniformity of our methods , our results vary widely across the six language pairs.
