A Long Hard Look at MWEs in the Age of Language Models | Vered Shwartz | in recent years , language models \( lms \) have become almost synonymous with nlp. pre-trained to “read” a large text corpus , such models are useful as both a representation layer as well as a source of world knowledge. but how well do they represent mwes \? this talk will discuss various problems in representing mwes , and the extent to which lms address them: • do lms capture the implicit relationship between constituents in compositional mwes \( from baby oil through parsley cake to cheeseburger stabbing \) \? • do lms recognize when words are used nonliterally in non-compositional mwes \( e.g. do they know whether there are fleas in the flea market \) \? • do lms know idioms , and can they infer the meaning of new idioms from the context as humans often do \?
