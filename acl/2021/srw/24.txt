Changing the Basis of Contextual Representations with Explicit Semantics | Tam√°s Ficsor | the application of transformer-based contextual representations has became a de facto solution for solving complex nlp tasks. despite their successes , such representations are arguably opaque as their latent dimensions are not directly interpretable. to alleviate this limitation of contextual representations , we devise such an algorithm where the output representation expresses human-interpretable information of each dimension. we achieve this by constructing a transformation matrix based on the semantic content of the embedding space and predefined semantic categories using hellinger distance. we evaluate our inferred representations on supersense prediction task. our experiments reveal that the interpretable nature of transformed contextual representations makes it possible to accurately predict the supersense category of a word by simply looking for its transformed coordinate with the largest coefficient. we quantify the effects of our proposed transformation when applied over traditional dense contextual embeddings. we additionally investigate and report consistent improvements for the integration of sparse contextual word representations into our proposed algorithm.
