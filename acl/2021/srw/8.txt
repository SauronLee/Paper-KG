Video-guided Machine Translation with Spatial Hierarchical Attention Network | Weiqi Gu | video-guided machine translation , as one type of multimodal machine translations , aims to engage video contents as auxiliary information to address the word sense ambiguity problem in machine translation. previous studies only use features from pretrained action detection models as motion representations of the video to solve the verb sense ambiguity , leaving the noun sense ambiguity a problem. to address this problem , we propose a video-guided machine translation system by using both spatial and motion representations in videos. for spatial features , we propose a hierarchical attention network to model the spatial information from object-level to video-level. experiments on the vatex dataset show that our system achieves 35.86 bleu-4 score , which is 0.51 score higher than the single model of the sota method.
