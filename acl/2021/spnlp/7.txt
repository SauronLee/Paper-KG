Comparing Span Extraction Methods for Semantic Role Labeling | Zhisong Zhang | in this work , we empirically compare span extraction methods for the task of semantic role labeling \( srl \) . while recent progress incorporating pre-trained contextualized representations into neural encoders has greatly improved srl f1 performance on popular benchmarks , the potential costs and benefits of structured decoding in these models have become less clear. with extensive experiments on propbank srl datasets , we find that more structured decoding methods outperform bio-tagging when using static \( word type \) embeddings across all experimental settings. however , when used in conjunction with pre-trained contextualized word representations , the benefits are diminished. we also experiment in cross-genre and cross-lingual settings and find similar trends. we further perform speed comparisons and provide analysis on the accuracy-efficiency trade-offs among different decoding methods.
