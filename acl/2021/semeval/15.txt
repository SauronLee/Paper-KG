SkoltechNLP at SemEval-2021 Task 2: Generating Cross-Lingual Training Data for the Word-in-Context Task | Anton Razzhigaev | in this paper , we present a system for the solution of the cross-lingual and multilingual word-in-context disambiguation task. task organizers provided monolingual data in several languages , but no cross-lingual training data were available. to address the lack of the officially provided cross-lingual training data , we decided to generate such data ourselves. we describe a simple yet effective approach based on machine translation and back translation of the lexical units to the original language used in the context of this shared task. in our experiments , we used a neural system based on the xlm-r , a pre-trained transformer-based masked language model , as a baseline. we show the effectiveness of the proposed approach as it allows to substantially improve the performance of this strong neural baseline model. in addition , in this study , we present multiple types of the xlm-r based classifier , experimenting with various ways of mixing information from the first and second occurrences of the target word in two samples.
