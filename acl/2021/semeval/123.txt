MIPT-NSU-UTMN at SemEval-2021 Task 5: Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection | Mikhail Kotyushev | this paper describes our system for semeval-2021 task 5 on toxic spans detection. we developed ensemble models using bert-based neural architectures and post-processing to combine tokens into spans. we evaluated several pre-trained language models using various ensemble techniques for toxic span identification and achieved sizable improvements over our baseline fine-tuned bert models. finally , our system obtained a f1-score of 67.55% on test data.
