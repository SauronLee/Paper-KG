AIMH at SemEval-2021 Task 6: Multimodal Classification Using an Ensemble of Transformer Models | Nicola Messina | this paper describes the system used by the aimh team to approach the semeval task 6. we propose an approach that relies on an architecture based on the transformer model to process multimodal content \( text and images \) in memes. our architecture , called dvtt \( double visual textual transformer \) , approaches subtasks 1 and 3 of task 6 as multi-label classification problems , where the text and/or images of the meme are processed , and the probabilities of the presence of each possible persuasion technique are returned as a result. dvtt uses two complete networks of transformers that work on text and images that are mutually conditioned. one of the two modalities acts as the main one and the second one intervenes to enrich the first one , thus obtaining two distinct ways of operation. the two transformers outputs are merged by averaging the inferred probabilities for each possible label , and the overall network is trained end-to-end with a binary cross-entropy loss.
