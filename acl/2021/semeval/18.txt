ReCAM@IITK at SemEval-2021 Task 4: BERT and ALBERT based Ensemble for Abstract Word Prediction | Abhishek Mittal | this paper describes our system for task 4 of semeval-2021: reading comprehension of abstract meaning \( recam \) . we participated in all subtasks where the main goal was to predict an abstract word missing from a statement. we fine-tuned the pre-trained masked language models namely bert and albert and used an ensemble of these as our submitted system on subtask 1 \( recam-imperceptibility \) and subtask 2 \( recam-nonspecificity \) . for subtask 3 \( recam-intersection \) , we submitted the albert model as it gives the best results. we tried multiple approaches and found that masked language modeling \( mlm \) based approach works the best.
