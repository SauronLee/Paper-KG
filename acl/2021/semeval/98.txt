LU-BZU at SemEval-2021 Task 2: Word2Vec and Lemma2Vec performance in Arabic Word-in-Context disambiguation | Moustafa Al-Hajj | this paper presents a set of experiments to evaluate and compare between the performance of using cbow word2vec and lemma2vec models for arabic word-in-context \( wic \) disambiguation without using sense inventories or sense embeddings. as part of the semeval-2021 shared task 2 on wic disambiguation , we used the dev.ar-ar dataset \( 2k sentence pairs \) to decide whether two words in a given sentence pair carry the same meaning. we used two word2vec models: wiki-cbow , a pre-trained model on arabic wikipedia , and another model we trained on large arabic corpora of about 3 billion tokens. two lemma2vec models was also constructed based on the two word2vec models. each of the four models was then used in the wic disambiguation task , and then evaluated on the semeval-2021 test.ar-ar dataset. at the end , we reported the performance of different models and compared between using lemma-based and word-based models.
