Cambridge at SemEval-2021 Task 2: Neural WiC-Model with Data Augmentation and Exploration of Representation | Zheng Yuan | this paper describes the system of the cambridge team submitted to the semeval-2021 shared task on multilingual and cross-lingual word-in-context disambiguation. building on top of a pre-trained masked language model , our system is first pre-trained on out-of-domain data , and then fine-tuned on in-domain data. we demonstrate the effectiveness of the proposed two-step training strategy and the benefits of data augmentation from both existing examples and new resources. we further investigate different representations and show that the addition of distance-based features is helpful in the word-in-context disambiguation task. our system yields highly competitive results in the cross-lingual track without training on any cross-lingual data; and achieves state-of-the-art results in the multilingual track , ranking first in two languages \( arabic and russian \) and second in french out of 171 submitted systems.
