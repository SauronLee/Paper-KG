ITNLP at SemEval-2021 Task 11: Boosting BERT with Sampling and Adversarial Training for Knowledge Extraction | Genyu Zhang | this paper describes the winning system in the end-to-end pipeline phase for the nlpcontributiongraph task. the system is composed of three bert-based models and the three models are used to extract sentences , entities and triples respectively. experiments show that sampling and adversarial training can greatly boost the system. in end-to-end pipeline phase , our system got an average f1 of 0.4703 , significantly higher than the second-placed system which got an average f1 of 0.3828.
