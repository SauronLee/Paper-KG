MCL@IITK at SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation using Augmented Data, Signals, and Transformers | Rohan Gupta | in this work , we present our approach for solving the semeval 2021 task 2: multilingual and cross-lingual word-in-context disambiguation \( mcl-wic \) . the task is a sentence pair classification problem where the goal is to detect whether a given word common to both the sentences evokes the same meaning. we submit systems for both the settings - multilingual \( the pair’s sentences belong to the same language \) and cross-lingual \( the pair’s sentences belong to different languages \) . the training data is provided only in english. consequently , we employ cross-lingual transfer techniques. our approach employs fine-tuning pre-trained transformer-based language models , like electra and albert , for the english task and xlm-r for all other tasks. to improve these systems’ performance , we propose adding a signal to the word to be disambiguated and augmenting our data by sentence pair reversal. we further augment the dataset provided to us with wic , xl-wic and semcor 3.0. using ensembles , we achieve strong performance in the multilingual task , placing first in the en-en and fr-fr sub-tasks. for the cross-lingual setting , we employed translate-test methods and a zero-shot method , using our multilingual models , with the latter performing slightly better.
