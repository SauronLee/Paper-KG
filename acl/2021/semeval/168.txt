DuluthNLP at SemEval-2021 Task 7: Fine-Tuning RoBERTa Model for Humor Detection and Offense Rating | Samuel Akrah | this paper presents the duluthnlp submission to task 7 of the semeval 2021 competition on detecting and rating humor and offense. in it , we explain the approach used to train the model together with the process of fine-tuning our model in getting the results. we focus on humor detection , rating , and of-fense rating , representing three out of the four subtasks that were provided. we show that optimizing hyper-parameters for learning rate , batch size and number of epochs can increase the accuracy and f1 score for humor detection
