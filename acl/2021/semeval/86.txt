cs60075_team2 at SemEval-2021 Task 1 : Lexical Complexity Prediction using Transformer-based Language Models pre-trained on various text corpora | Abhilash Nandy | the main contribution of this paper is to fine-tune transformer-based language models pre-trained on several text corpora , some being general \( e.g. , wikipedia , bookscorpus \) , some being the corpora from which the complex dataset was extracted , and others being from other specific domains such as finance , law , etc. we perform ablation studies on selecting the transformer models and how their individual complexity scores are aggregated to get the resulting complexity scores. our method achieves a best pearson correlation of 0.784 in sub-task 1 \( single word \) and 0.836 in sub-task 2 \( multiple word expressions \) .
