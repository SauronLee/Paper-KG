IIE-NLP-Eyas at SemEval-2021 Task 4: Enhancing PLM for ReCAM with Special Tokens, Re-Ranking, Siamese Encoders and Back Translation | Yuqiang Xie | this paper introduces our systems for all three subtasks of semeval-2021 task 4: reading comprehension of abstract meaning. to help our model better represent and understand abstract concepts in natural language , we well-design many simple and effective approaches adapted to the backbone model \( roberta \) . specifically , we formalize the subtasks into the multiple-choice question answering format and add special tokens to abstract concepts , then , the final prediction of qa is considered as the result of subtasks. additionally , we employ many finetuning tricks to improve the performance. experimental results show that our approach gains significant performance compared with the baseline systems. our system achieves eighth rank \( 87.51% \) and tenth rank \( 89.64% \) on the official blind test set of subtask 1 and subtask 2 respectively.
