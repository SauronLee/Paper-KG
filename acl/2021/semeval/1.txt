OCHADAI-KYOTO at SemEval-2021 Task 1: Enhancing Model Generalization and Robustness for Lexical Complexity Prediction | Yuki Taya | we propose an ensemble model for predicting the lexical complexity of words and multiword expressions \( mwes \) . the model receives as input a sentence with a target word or mwe and outputs its complexity score. given that a key challenge with this task is the limited size of annotated data , our model relies on pretrained contextual representations from different state-of-the-art transformer-based language models \( i.e. , bert and roberta \) , and on a variety of training methods for further enhancing model generalization and robustness: multi-step fine-tuning and multi-task learning , and adversarial training. additionally , we propose to enrich contextual representations by adding hand-crafted features during training. our model achieved competitive results and ranked among the top-10 systems in both sub-tasks.
