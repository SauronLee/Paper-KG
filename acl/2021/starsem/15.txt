One Semantic Parser to Parse Them All: Sequence to Sequence Multi-Task Learning on Semantic Parsing Datasets | Marco Damonte | semantic parsers map natural language utterances to meaning representations. the lack of a single standard for meaning representations led to the creation of a plethora of semantic parsing datasets. to unify different datasets and train a single model for them , we investigate the use of multi-task learning \( mtl \) architectures. we experiment with five datasets \( geoquery , nlmaps , top , overnight , amr \) . we find that an mtl architecture that shares the entire network across datasets yields competitive or better parsing accuracies than the single-task baselines , while reducing the total number of parameters by 68%. we further provide evidence that mtl has also better compositional generalization than single-task models. we also present a comparison of task sampling methods and propose a competitive alternative to widespread proportional sampling strategies.
