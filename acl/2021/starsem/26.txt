Overcoming Poor Word Embeddings with Word Definitions | Christopher Malon | modern natural language understanding models depend on pretrained subword embeddings , but applications may need to reason about words that were never or rarely seen during pretraining. we show that examples that depend critically on a rarer word are more challenging for natural language inference models. then we explore how a model could learn to use definitions , provided in natural text , to overcome this handicap. our modelâ€™s understanding of a definition is usually weaker than a well-modeled word embedding , but it recovers most of the performance gap from using a completely untrained word.
