Denoising Word Embeddings by Averaging in a Shared Space | Avi Caciularu | we introduce a new approach for smoothing and improving the quality of word embeddings. we consider a method of fusing word embeddings that were trained on the same corpus but with different initializations. we project all the models to a shared vector space using an efficient implementation of the generalized procrustes analysis \( gpa \) procedure , previously used in multilingual word translation. our word representation demonstrates consistent improvements over the raw models as well as their simplistic average , on a range of tasks. as the new representations are more stable and reliable , there is a noticeable improvement in rare word evaluations.
