BiQuAD: Towards QA based on deeper text understanding | Frank Grimm | recent question answering and machine reading benchmarks frequently reduce the task to one of pinpointing spans within a certain text passage that answers the given question. typically , these systems are not required to actually understand the text on a deeper level that allows for more complex reasoning on the information contained. we introduce a new dataset called biquad that requires deeper comprehension in order to answer questions in both extractive and deductive fashion. the dataset consist of 4 , 190 closed-domain texts and a total of 99 , 149 question-answer pairs. the texts are synthetically generated soccer match reports that verbalize the main events of each match. all texts are accompanied by a structured datalog program that represents a \( logical \) model of its information. we show that state-of-the-art qa models do not perform well on the challenging long form contexts and reasoning requirements posed by the dataset. in particular , transformer based state-of-the-art models achieve f1-scores of only 39.0. we demonstrate how these synthetic datasets align structured knowledge with natural text and aid model introspection when approaching complex text understanding.
