Neural Retrieval for Question Answering with Cross-Attention Supervised Data Augmentation | Yinfei Yang | early fusion models with cross-attention have shown better-than-human performance on some question answer benchmarks , while it is a poor fit for retrieval since it prevents pre-computation of the answer representations. we present a supervised data mining method using an accurate early fusion model to improve the training of an efficient late fusion retrieval model. we first train an accurate classification model with cross-attention between questions and answers. the cross-attention model is then used to annotate additional passages in order to generate weighted training examples for a neural retrieval model. the resulting retrieval model with additional data significantly outperforms retrieval models directly trained with gold annotations on precision at n \( p@n \) and mean reciprocal rank \( mrr \) .
