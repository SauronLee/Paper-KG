Issues with Entailment-based Zero-shot Text Classification | Tingting Ma | the general format of natural language inference \( nli \) makes it tempting to be used for zero-shot text classification by casting any target label into a sentence of hypothesis and verifying whether or not it could be entailed by the input , aiming at generic classification applicable on any specified label space. in this opinion piece , we point out a few overlooked issues that are yet to be discussed in this line of work. we observe huge variance across different classification datasets amongst standard bert-based nli models and surprisingly find that pre-trained bert without any fine-tuning can yield competitive performance against bert fine-tuned for nli. with the concern that these models heavily rely on spurious lexical patterns for prediction , we also experiment with preliminary approaches for more robust nli , but the results are in general negative. our observations reveal implicit but challenging difficulties in entailment-based zero-shot text classification.
