AND does not mean OR: Using Formal Languages to Study Language Models’ Representations | Aaron Traylor | a current open question in natural language processing is to what extent language models , which are trained with access only to the form of language , are able to capture the meaning of language. this question is challenging to answer in general , as there is no clear line between meaning and form , but rather meaning constrains form in consistent ways. the goal of this study is to offer insights into a narrower but critical subquestion: under what conditions should we expect that meaning and form covary sufficiently , such that a language model with access only to form might nonetheless succeed in emulating meaning \? focusing on several formal languages \( propositional logic and a set of programming languages \) , we generate training corpora using a variety of motivated constraints , and measure a distributional language model’s ability to differentiate logical symbols \( and , or , and not \) . our findings are largely negative: none of our simulated training corpora result in models which definitively differentiate meaningfully different symbols \( e.g. , and vs. or \) , suggesting a limitation to the types of semantic signals that current models are able to exploit.
