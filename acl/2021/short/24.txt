Continual Quality Estimation with Online Bayesian Meta-Learning | Abiola Obamuyide | most current quality estimation \( qe \) models for machine translation are trained and evaluated in a static setting where training and test data are assumed to be from a fixed distribution. however , in real-life settings , the test data that a deployed qe model would be exposed to may differ from its training data. in particular , training samples are often labelled by one or a small set of annotators , whose perceptions of translation quality and needs may differ substantially from those of end-users , who will employ predictions in practice. to address this challenge , we propose an online bayesian meta-learning framework for the continuous training of qe models that is able to adapt them to the needs of different users , while being robust to distributional shifts in training and test data. experiments on data with varying number of users and language characteristics validate the effectiveness of the proposed approach.
