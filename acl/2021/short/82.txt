QA-Driven Zero-shot Slot Filling with Weak Supervision Pretraining | Xinya Du | slot-filling is an essential component for building task-oriented dialog systems. in this work , we focus on the zero-shot slot-filling problem , where the model needs to predict slots and their values , given utterances from new domains without training on the target domain. prior methods directly encode slot descriptions to generalize to unseen slot types. however , raw slot descriptions are often ambiguous and do not encode enough semantic information , limiting the modelsâ€™ zero-shot capability. to address this problem , we introduce qa-driven slot filling \( qasf \) , which extracts slot-filler spans from utterances with a span-based qa model. we use a linguistically motivated questioning strategy to turn descriptions into questions , allowing the model to generalize to unseen slot types. moreover , our qasf model can benefit from weak supervision signals from qa pairs synthetically generated from unlabeled conversations. our full system substantially outperforms baselines by over 5% on the snips benchmark.
