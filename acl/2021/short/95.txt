Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence | Federico Bianchi | topic models extract groups of words from documents , whose interpretation as a topic hopefully allows for a better understanding of the data. however , the resulting word groups are often not coherent , making them harder to interpret. recently , neural topic models have shown improvements in overall coherence. concurrently , contextual embeddings have advanced the state of the art of neural models in general. in this paper , we combine contextualized representations with neural topic models. we find that our approach produces more meaningful and coherent topics than traditional bag-of-words topic models and recent neural models. our results indicate that future improvements in language models will translate into better topic models.
