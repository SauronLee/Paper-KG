Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions | Daniel Rosenberg | deep learning algorithms have shown promising results in visual question answering \( vqa \) tasks , but a more careful look reveals that they often do not understand the rich signal they are being fed with. to understand and better measure the generalization capabilities of vqa systems , we look at their robustness to counterfactually augmented data. our proposed augmentations are designed to make a focused intervention on a specific property of the question such that the answer changes. using these augmentations , we propose a new robustness measure , robustness to augmented data \( rad \) , which measures the consistency of model predictions between original and augmented examples. through extensive experimentation , we show that rad , unlike classical accuracy measures , can quantify when state-of-the-art systems are not robust to counterfactuals. we find substantial failure cases which reveal that current vqa systems are still brittle. finally , we connect between robustness and generalization , demonstrating the predictive power of rad for performance on unseen augmentations.
