Addressing Semantic Drift in Generative Question Answering with Auxiliary Extraction | Chenliang Li | recently , question answering \( qa \) based on machine reading comprehension has become popular. this work focuses on generative qa which aims to generate an abstractive answer to a given question instead of extracting an answer span from a provided passage. generative qa often suffers from two critical problems: \( 1 \) summarizing content irrelevant to a given question , \( 2 \) drifting away from a correct answer during generation. in this paper , we address these problems by a novel rationale-enriched answer generator \( reag \) , which incorporates an extractive mechanism into a generative model. specifically , we add an extraction task on the encoder to obtain the rationale for an answer , which is the most relevant piece of text in an input document to a given question. based on the extracted rationale and original input , the decoder is expected to generate an answer with high confidence. we jointly train reag on the ms marco qa+nlg task and the experimental results show that reag improves the quality and semantic accuracy of answers over baseline models.
