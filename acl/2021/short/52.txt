Discrete Cosine Transform as Universal Sentence Encoder | Nada Almarwani | modern sentence encoders are used to generate dense vector representations that capture the underlying linguistic characteristics for a sequence of words , including phrases , sentences , or paragraphs. these kinds of representations are ideal for training a classifier for an end task such as sentiment analysis , question answering and text classification. different models have been proposed to efficiently generate general purpose sentence representations to be used in pretraining protocols. while averaging is the most commonly used efficient sentence encoder , discrete cosine transform \( dct \) was recently proposed as an alternative that captures the underlying syntactic characteristics of a given text without compromising practical efficiency compared to averaging. however , as with most other sentence encoders , the dct sentence encoder was only evaluated in english. to this end , we utilize dct encoder to generate universal sentence representation for different languages such as german , french , spanish and russian. the experimental results clearly show the superior effectiveness of dct encoding in which consistent performance improvements are achieved over strong baselines on multiple standardized datasets
