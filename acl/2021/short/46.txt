Adaptive Nearest Neighbor Machine Translation | Xin Zheng | knn-mt , recently proposed by khandelwal et al. \( 2020a \) , successfully combines pre-trained neural machine translation \( nmt \) model with token-level k-nearest-neighbor \( knn \) retrieval to improve the translation accuracy. however , the traditional knn algorithm used in knn-mt simply retrieves a same number of nearest neighbors for each target token , which may cause prediction errors when the retrieved neighbors include noises. in this paper , we propose adaptive knn-mt to dynamically determine the number of k for each target token. we achieve this by introducing a light-weight meta-k network , which can be efficiently trained with only a few training samples. on four benchmark machine translation datasets , we demonstrate that the proposed method is able to effectively filter out the noises in retrieval results and significantly outperforms the vanilla knn-mt model. even more noteworthy is that the meta-k network learned on one domain could be directly applied to other domains and obtain consistent improvements , illustrating the generality of our method. our implementation is open-sourced at https://github.com/zhengxxn/adaptive-knn-mt.
