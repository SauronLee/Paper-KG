Measuring and Improving BERT’s Mathematical Abilities by Predicting the Order of Reasoning. | Piotr Piękos | imagine you are in a supermarket. you have two bananas in your basket and want to buy four apples. how many fruits do you have in total \? this seemingly straightforward question can be challenging for data-driven language models , even if trained at scale. however , we would expect such generic language models to possess some mathematical abilities in addition to typical linguistic competence. towards this goal , we investigate if a commonly used language model , bert , possesses such mathematical abilities and , if so , to what degree. for that , we fine-tune bert on a popular dataset for word math problems , aqua-rat , and conduct several tests to understand learned representations better. since we teach models trained on natural language to do formal mathematics , we hypothesize that such models would benefit from training on semi-formal steps that explain how math results are derived. to better accommodate such training , we also propose new pretext tasks for learning mathematical rules. we call them \( neighbor \) reasoning order prediction \( rop or nrop \) . with this new model , we achieve significantly better outcomes than data-driven baselines and even on-par with more tailored models.
