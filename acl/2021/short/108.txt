Embracing Ambiguity: Shifting the Training Target of NLI Models | Johannes Mario Meissner | natural language inference \( nli \) datasets contain examples with highly ambiguous labels. while many research works do not pay much attention to this fact , several recent efforts have been made to acknowledge and embrace the existence of ambiguity , such as unli and chaosnli. in this paper , we explore the option of training directly on the estimated label distribution of the annotators in the nli task , using a learning loss based on this ambiguity distribution instead of the gold-labels. we prepare ambinli , a trial dataset obtained from readily available sources , and show it is possible to reduce chaosnli divergence scores when finetuning on this data , a promising first step towards learning how to capture linguistic ambiguity. additionally , we show that training on the same amount of data but targeting the ambiguity distribution instead of gold-labels can result in models that achieve higher performance and learn better representations for downstream tasks.
