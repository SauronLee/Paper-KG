HILDIF: Interactive Debugging of NLI Models Using Influence Functions | Hugo Zylberajch | biases and artifacts in training data can cause unwelcome behavior in text classifiers \( such as shallow pattern matching \) , leading to lack of generalizability. one solution to this problem is to include users in the loop and leverage their feedback to improve models. we propose a novel explanatory debugging pipeline called hildif , enabling humans to improve deep text classifiers using influence functions as an explanation method. we experiment on the natural language inference \( nli \) task , showing that hildif can effectively alleviate artifact problems in fine-tuned bert models and result in increased model generalizability.
