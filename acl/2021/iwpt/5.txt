Translate, then Parse! A Strong Baseline for Cross-Lingual AMR Parsing | Sarah Uhrig | in cross-lingual abstract meaning representation \( amr \) parsing , researchers develop models that project sentences from various languages onto their amrs to capture their essential semantic structures: given a sentence in any language , we aim to capture its core semantic content through concepts connected by manifold types of semantic relations. methods typically leverage large silver training data to learn a single model that is able to project non-english sentences to amrs. however , we find that a simple baseline tends to be overlooked: translating the sentences to english and projecting their amr with a monolingual amr parser \( translate+parse , t+p \) . in this paper , we revisit this simple two-step base-line , and enhance it with a strong nmt system and a strong amr parser. our experiments show that t+p outperforms a recent state-of-the-art system across all tested languages: german , italian , spanish and mandarin with +14.6 , +12.6 , +14.3 and +16.0 smatch points
