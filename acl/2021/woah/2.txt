HateBERT: Retraining BERT for Abusive Language Detection in English | Tommaso Caselli | we introduce hatebert , a re-trained bert model for abusive language detection in english. the model was trained on ral-e , a large-scale dataset of reddit comments in english from communities banned for being offensive , abusive , or hateful that we have curated and made available to the public. we present the results of a detailed comparison between a general pre-trained language model and the retrained version on three english datasets for offensive , abusive language and hate speech detection tasks. in all datasets , hatebert outperforms the corresponding general bert model. we also discuss a battery of experiments comparing the portability of the fine-tuned models across the datasets , suggesting that portability is affected by compatibility of the annotated phenomena.
