Modeling Profanity and Hate Speech in Social Media with Semantic Subspaces | Vanessa Hahn | hate speech and profanity detection suffer from data sparsity , especially for languages other than english , due to the subjective nature of the tasks and the resulting annotation incompatibility of existing corpora. in this study , we identify profane subspaces in word and sentence representations and explore their generalization capability on a variety of similar and distant target tasks in a zero-shot setting. this is done monolingually \( german \) and cross-lingually to closely-related \( english \) , distantly-related \( french \) and non-related \( arabic \) tasks. we observe that , on both similar and distant target tasks and across all languages , the subspace-based representations transfer more effectively than standard bert representations in the zero-shot setting , with improvements between f1 +10.9 and f1 +42.9 over the baselines across all tested monolingual and cross-lingual scenarios.
