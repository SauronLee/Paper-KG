Exploiting Auxiliary Data for Offensive Language Detection with Bidirectional Transformers | Sumer Singh | offensive language detection \( old \) has received increasing attention due to its societal impact. recent work shows that bidirectional transformer based methods obtain impressive performance on old. however , such methods usually rely on large-scale well-labeled old datasets for model training. to address the issue of data/label scarcity in old , in this paper , we propose a simple yet effective domain adaptation approach to train bidirectional transformers. our approach introduces domain adaptation \( da \) training procedures to albert , such that it can effectively exploit auxiliary data from source domains to improve the old performance in a target domain. experimental results on benchmark datasets show that our approach , albert \( da \) , obtains the state-of-the-art performance in most cases. particularly , our approach significantly benefits underrepresented and under-performing classes , with a significant improvement over albert.
