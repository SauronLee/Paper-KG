ProphetNet-X: Large-Scale Pre-training Models for English, Chinese, Multi-lingual, Dialog, and Code Generation | Weizhen Qi | now , the pre-training technique is ubiquitous in natural language processing field. prophetnet is a pre-training based natural language generation method which shows powerful performance on english text summarization and question generation tasks. in this paper , we extend prophetnet into other domains and languages , and present the prophetnet family pre-training models , named prophetnet-x , where x can be english , chinese , multi-lingual , and so on. we pre-train a cross-lingual generation model prophetnet-multi , a chinese generation model prophetnet-zh , two open-domain dialog generation models prophetnet-dialog-en and prophetnet-dialog-zh. and also , we provide a plg \( programming language generation \) model prophetnet-code to show the generation performance besides nlg \( natural language generation \) tasks. in our experiments , prophetnet-x models achieve new state-of-the-art performance on 10 benchmarks. all the models of prophetnet-x share the same model structure , which allows users to easily switch between different models. we make the code and models publicly available , and we will keep updating more pre-training models and finetuning scripts.
