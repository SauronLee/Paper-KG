Modeling Discourse Structure for Document-level Neural Machine Translation | Junxuan Chen | recently , document-level neural machine translation \( nmt \) has become a hot topic in the community of machine translation. despite its success , most of existing studies ignored the discourse structure information of the input document to be translated , which has shown effective in other tasks. in this paper , we propose to improve document-level nmt with the aid of discourse structure information. our encoder is based on a hierarchical attention network \( han \) \( miculicich et al. , 2018 \) . specifically , we first parse the input document to obtain its discourse structure. then , we introduce a transformer-based path encoder to embed the discourse structure information of each word. finally , we combine the discourse structure information with the word embedding before it is fed into the encoder. experimental results on the english-to-german dataset show that our model can significantly outperform both transformer and transformer+han.
