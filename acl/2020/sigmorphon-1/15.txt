One Model to Pronounce Them All: Multilingual Grapheme-to-Phoneme Conversion With a Transformer Ensemble | Kaili Vesik | the task of grapheme-to-phoneme \( g2p \) conversion is important for both speech recognition and synthesis. similar to other speech and language processing tasks , in a scenario where only small-sized training data are available , learning g2p models is challenging. we describe a simple approach of exploiting model ensembles , based on multilingual transformers and self-training , to develop a highly effective g2p solution for 15 languages. our models are developed as part of our participation in the sigmorphon 2020 shared task 1 focused at g2p. our best models achieve 14.99 word error rate \( wer \) and 3.30 phoneme error rate \( per \) , a sizeable improvement over the shared task competitive baselines.
