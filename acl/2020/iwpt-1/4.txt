Semi-supervised Parsing with a Variational Autoencoding Parser | Xiao Zhang | we propose an end-to-end variational autoencoding parsing \( vap \) model for semi-supervised graph-based projective dependency parsing. it encodes the input using continuous latent variables in a sequential manner by deep neural networks \( dnn \) that can utilize the contextual information , and reconstruct the input using a generative model. the vap model admits a unified structure with different loss functions for labeled and unlabeled data with shared parameters. we conducted experiments on the wsj data sets , showing the proposed model can use the unlabeled data to increase the performance on a limited amount of labeled data , on a par with a recently proposed semi-supervised parser with faster inference.
