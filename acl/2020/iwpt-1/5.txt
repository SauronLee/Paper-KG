Memory-bounded Neural Incremental Parsing for Psycholinguistic Prediction | Lifeng Jin | syntactic surprisal has been shown to have an effect on human sentence processing , and can be predicted from prefix probabilities of generative incremental parsers. recent state-of-the-art incremental generative neural parsers are able to produce accurate parses and surprisal values but have unbounded stack memory , which may be used by the neural parser to maintain explicit in-order representations of all previously parsed words , inconsistent with results of human memory experiments. in contrast , humans seem to have a bounded working memory , demonstrated by inhibited performance on word recall in multi-clause sentences \( bransford and franks , 1971 \) , and on center-embedded sentences \( miller and isard , 1964 \) . bounded statistical parsers exist , but are less accurate than neural parsers in predict-ing reading times. this paper describes a neural incremental generative parser that is able to provide accurate surprisal estimates and can be constrained to use a bounded stack. results show that the accuracy gains of neural parsers can be reliably extended to psycholinguistic modeling without risk of distortion due to un-bounded working memory.
