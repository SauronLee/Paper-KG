Lexicalization of Probabilistic Linear Context-free Rewriting Systems | Richard Mörbitz | in the field of constituent parsing , probabilistic grammar formalisms have been studied to model the syntactic structure of natural language. more recently , approaches utilizing neural models gained lots of traction in this field , as they achieved accurate results at high speed. we aim for a symbiosis between probabilistic linear context-free rewriting systems \( plcfrs \) as a probabilistic grammar formalism and neural models to get the best of both worlds: the interpretability of grammars , and the speed and accuracy of neural models. to combine these two , we consider the approach of supertagging that requires lexicalized grammar formalisms. here , we present a procedure which turns any plcfrs g into an equivalent lexicalized plcfrs g’. the derivation trees in g’ are then mapped to equivalent derivations in g. our construction for g’ preserves the probability assignment and does not increase parsing complexity compared to g.
