Generating Medical Reports from Patient-Doctor Conversations Using Sequence-to-Sequence Models | Seppo Enarvi | we discuss automatic creation of medical reports from asr-generated patient-doctor conversational transcripts using an end-to-end neural summarization approach. we explore both recurrent neural network \( rnn \) and transformer-based sequence-to-sequence architectures for summarizing medical conversations. we have incorporated enhancements to these architectures , such as the pointer-generator network that facilitates copying parts of the conversations to the reports , and a hierarchical rnn encoder that makes rnn training three times faster with long inputs. a comparison of the relative improvements from the different model architectures over an oracle extractive baseline is provided on a dataset of 800k orthopedic encounters. consistent with observations in literature for machine translation and related tasks , we find the transformer models outperform rnn in accuracy , while taking less than half the time to train. significantly large wins over a strong oracle baseline indicate that sequence-to-sequence modeling is a promising approach for automatic generation of medical reports , in the presence of data at scale.
