Robust Prediction of Punctuation and Truecasing for Medical ASR | Monica Sunkara | automatic speech recognition \( asr \) systems in the medical domain that focus on transcribing clinical dictations and doctor-patient conversations often pose many challenges due to the complexity of the domain. asr output typically undergoes automatic punctuation to enable users to speak naturally , without having to vocalize awkward and explicit punctuation commands , such as “period” , “add comma” or “exclamation point” , while truecasing enhances user readability and improves the performance of downstream nlp tasks. this paper proposes a conditional joint modeling framework for prediction of punctuation and truecasing using pretrained masked language models such as bert , biobert and roberta. we also present techniques for domain and task specific adaptation by fine-tuning masked language models with medical domain data. finally , we improve the robustness of the model against common errors made in asr by performing data augmentation. experiments performed on dictation and conversational style corpora show that our proposed model achieves 5% absolute improvement on ground truth text and 10% improvement on asr outputs over baseline models under f1 metric.
