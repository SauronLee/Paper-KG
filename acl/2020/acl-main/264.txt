Towards Understanding Gender Bias in Relation Extraction | Andrew Gaut | recent developments in neural relation extraction \( nre \) have made significant strides towards automated knowledge base construction. while much attention has been dedicated towards improvements in accuracy , there have been no attempts in the literature to evaluate social biases exhibited in nre systems. in this paper , we create wikigenderbias , a distantly supervised dataset composed of over 45 , 000 sentences including a 10% human annotated test set for the purpose of analyzing gender bias in relation extraction systems. we find that when extracting spouse-of and hypernym \( i.e. , occupation \) relations , an nre system performs differently when the gender of the target entity is different. however , such disparity does not appear when extracting relations such as birthdate or birthplace. we also analyze how existing bias mitigation techniques , such as name anonymization , word embedding debiasing , and data augmentation affect the nre system in terms of maintaining the test performance and reducing biases. unfortunately , due to nre models rely heavily on surface level cues , we find that existing bias mitigation approaches have a negative effect on nre. our analysis lays groundwork for future quantifying and mitigating bias in nre.
