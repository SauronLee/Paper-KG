Uncertain Natural Language Inference | Tongfei Chen | we introduce uncertain natural language inference \( unli \) , a refinement of natural language inference \( nli \) that shifts away from categorical labels , targeting instead the direct prediction of subjective probability assessments. we demonstrate the feasibility of collecting annotations for unli by relabeling a portion of the snli dataset under a probabilistic scale , where items even with the same categorical label differ in how likely people judge them to be true given a premise. we describe a direct scalar regression modeling approach , and find that existing categorically-labeled nli data can be used in pre-training. our best models correlate well with humans , demonstrating models are capable of more subtle inferences than the categorical bin assignment employed in current nli tasks.
