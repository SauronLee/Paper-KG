Generative Semantic Hashing Enhanced via Boltzmann Machines | Lin Zheng | generative semantic hashing is a promising technique for large-scale information retrieval thanks to its fast retrieval speed and small memory footprint. for the tractability of training , existing generative-hashing methods mostly assume a factorized form for the posterior distribution , enforcing independence among the bits of hash codes. from the perspectives of both model representation and code space size , independence is always not the best assumption. in this paper , to introduce correlations among the bits of hash codes , we propose to employ the distribution of boltzmann machine as the variational posterior. to address the intractability issue of training , we first develop an approximate method to reparameterize the distribution of a boltzmann machine by augmenting it as a hierarchical concatenation of a gaussian-like distribution and a bernoulli distribution. based on that , an asymptotically-exact lower bound is further derived for the evidence lower bound \( elbo \) . with these novel techniques , the entire model can be optimized efficiently. extensive experimental results demonstrate that by effectively modeling correlations among different bits within a hash code , our model can achieve significant performance gains.
