Generating Fact Checking Explanations | Pepa Atanasova | most existing work on automated fact checking is concerned with predicting the veracity of claims based on metadata , social network spread , language used in claims , and , more recently , evidence supporting or denying claims. a crucial piece of the puzzle that is still missing is to understand how to automate the most elaborate part of the process â€“ generating justifications for verdicts on claims. this paper provides the first study of how these explanations can be generated automatically based on available claim context , and how this task can be modelled jointly with veracity prediction. our results indicate that optimising both objectives at the same time , rather than training them separately , improves the performance of a fact checking system. the results of a manual evaluation further suggest that the informativeness , coverage and overall quality of the generated explanations are also improved in the multi-task model.
