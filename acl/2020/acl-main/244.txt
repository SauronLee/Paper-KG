Robust Encodings: A Framework for Combating Adversarial Typos | Erik Jones | despite excellent performance on many tasks , nlp systems are easily fooled by small adversarial perturbations of inputs. existing procedures to defend against such perturbations are either \( i \) heuristic in nature and susceptible to stronger attacks or \( ii \) provide guaranteed robustness to worst-case attacks , but are incompatible with state-of-the-art models like bert. in this work , we introduce robust encodings \( roben \) : a simple framework that confers guaranteed robustness , without making compromises on model architecture. the core component of roben is an encoding function , which maps sentences to a smaller , discrete space of encodings. systems using these encodings as a bottleneck confer guaranteed robustness with standard training , and the same encodings can be used across multiple tasks. we identify two desiderata to construct robust encoding functions: perturbations of a sentence should map to a small set of encodings \( stability \) , and models using encodings should still perform well \( fidelity \) . we instantiate roben to defend against a large family of adversarial typos. across six tasks from glue , our instantiation of roben paired with bert achieves an average robust accuracy of 71.3% against all adversarial typos in the family considered , while previous work using a typo-corrector achieves only 35.3% accuracy against a simple greedy attack.
