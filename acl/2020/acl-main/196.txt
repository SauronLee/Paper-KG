SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization | Haoming Jiang | transfer learning has fundamentally changed the landscape of natural language processing \( nlp \) . many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. however , due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models , aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. to address such an issue in a principled manner , we propose a new learning framework for robust and efficient fine-tuning for pre-trained models to attain better generalization performance. the proposed framework contains two important ingredients: 1. smoothness-inducing regularization , which effectively manages the complexity of the model; 2. bregman proximal point optimization , which is an instance of trust-region methods and can prevent aggressive updating. our experiments show that the proposed framework achieves new state-of-the-art performance on a number of nlp tasks including glue , snli , scitail and anli. moreover , it also outperforms the state-of-the-art t5 model , which is the largest pre-trained model containing 11 billion parameters , on glue.
