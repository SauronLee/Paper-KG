Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension | Hongyu Gong | in this paper , we study machine reading comprehension \( mrc \) on long texts: where a model takes as inputs a lengthy document and a query , extracts a text span from the document as an answer. state-of-the-art models \( e.g. , bert \) tend to use a stack of transformer layers that are pre-trained from a large number of unlabeled language corpora to encode the joint contextual information of query and document. however , these transformer models can only take as input a fixed-length \( e.g. , 512 \) text. to deal with even longer text inputs , previous approaches usually chunk them into
