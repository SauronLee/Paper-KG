DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim Verification | Lianwei Wu | recently , many methods discover effective evidence from reliable sources by appropriate neural networks for explainable claim verification , which has been widely recognized. however , in these methods , the discovery process of evidence is nontransparent and unexplained. simultaneously , the discovered evidence is aimed at the interpretability of the whole sequence of claims but insufficient to focus on the false parts of claims. in this paper , we propose a decision tree-based co-attention model \( dtca \) to discover evidence for explainable claim verification. specifically , we first construct decision tree-based evidence model \( dte \) to select comments with high credibility as evidence in a transparent and interpretable way. then we design co-attention self-attention networks \( casa \) to make the selected evidence interact with claims , which is for 1 \) training dte to determine the optimal decision thresholds and obtain more powerful evidence; and 2 \) utilizing the evidence to find the false parts in the claim. experiments on two public datasets , rumoureval and pheme , demonstrate that dtca not only provides explanations for the results of claim verification but also achieves the state-of-the-art performance , boosting the f1-score by more than 3.11% , 2.41% , respectively.
