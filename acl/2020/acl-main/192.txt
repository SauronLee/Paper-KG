Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling | Ouyu Lan | sequence labeling is a fundamental task for a range of natural language processing problems. when used in practice , its performance is largely influenced by the annotation quality and quantity , and meanwhile , obtaining ground truth labels is often costly. in many cases , ground truth labels do not exist , but noisy annotations or annotations from different domains are accessible. in this paper , we propose a novel framework consensus network \( connet \) that can be trained on annotations from multiple sources \( e.g. , crowd annotation , cross-domain data \) . it learns individual representation for every source and dynamically aggregates source-specific knowledge by a context-aware attention module. finally , it leads to a model reflecting the agreement \( consensus \) among multiple sources. we evaluate the proposed framework in two practical settings of multi-source learning: learning with crowd annotations and unsupervised cross-domain model adaptation. extensive experimental results show that our model achieves significant improvements over existing methods in both settings. we also demonstrate that the method can apply to various tasks and cope with different encoders.
