Autoencoding Pixies: Amortised Variational Inference with Graph Convolutions for Functional Distributional Semantics | Guy Emerson | functional distributional semantics provides a linguistically interpretable framework for distributional semantics , by representing the meaning of a word as a function \( a binary classifier \) , instead of a vector. however , the large number of latent variables means that inference is computationally expensive , and training a model is therefore slow to converge. in this paper , i introduce the pixie autoencoder , which augments the generative model of functional distributional semantics with a graph-convolutional neural network to perform amortised variational inference. this allows the model to be trained more effectively , achieving better results on two tasks \( semantic similarity in context and semantic composition \) , and outperforming bert , a large pre-trained language model.
