Norm-Based Curriculum Learning for Neural Machine Translation | Xuebo Liu | a neural machine translation \( nmt \) system is expensive to train , especially with high-resource settings. as the nmt architectures become deeper and wider , this issue gets worse and worse. in this paper , we aim to improve the efficiency of training an nmt by introducing a novel norm-based curriculum learning method. we use the norm \( aka length or module \) of a word embedding as a measure of 1 \) the difficulty of the sentence , 2 \) the competence of the model , and 3 \) the weight of the sentence. the norm-based sentence difficulty takes the advantages of both linguistically motivated and model-based sentence difficulties. it is easy to determine and contains learning-dependent features. the norm-based model competence makes nmt learn the curriculum in a fully automated way , while the norm-based sentence weight further enhances the learning of the vector representation of the nmt. experimental results for the wmt’14 english-german and wmt’17 chinese-english translation tasks demonstrate that the proposed method outperforms strong baselines in terms of bleu score \( +1.17/+1.56 \) and training speedup \( 2.22x/3.33x \) .
