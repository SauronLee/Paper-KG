Measuring Forecasting Skill from Text | Shi Zong | people vary in their ability to make accurate predictions about the future. prior studies have shown that some individuals can predict the outcome of future events with consistently better accuracy. this leads to a natural question: what makes some forecasters better than others \? in this paper we explore connections between the language people use to describe their predictions and their forecasting skill. datasets from two different forecasting domains are explored: \( 1 \) geopolitical forecasts from good judgment open , an online prediction forum and \( 2 \) a corpus of company earnings forecasts made by financial analysts. we present a number of linguistic metrics which are computed over text associated with peopleâ€™s predictions about the future including: uncertainty , readability , and emotion. by studying linguistic factors associated with predictions , we are able to shed some light on the approach taken by skilled forecasters. furthermore , we demonstrate that it is possible to accurately predict forecasting skill using a model that is based solely on language. this could potentially be useful for identifying accurate predictions or potentially skilled forecasters earlier.
