DoQA - Accessing Domain-Specific FAQs via Conversational QA | Jon Ander Campos | the goal of this work is to build conversational question answering \( qa \) interfaces for the large body of domain-specific information available in faq sites. we present doqa , a dataset with 2 , 437 dialogues and 10 , 917 qa pairs. the dialogues are collected from three stack exchange sites using the wizard of oz method with crowdsourcing. compared to previous work , doqa comprises well-defined information needs , leading to more coherent and natural conversations with less factoid questions and is multi-domain. in addition , we introduce a more realistic information retrieval \( ir \) scenario where the system needs to find the answer in any of the faq documents. the results of an existing , strong , system show that , thanks to transfer learning from a wikipedia qa dataset and fine tuning on a single faq domain , it is possible to build high quality conversational qa systems for faqs without in-domain training data. the good results carry over into the more challenging ir scenario. in both cases , there is still ample room for improvement , as indicated by the higher human upperbound.
