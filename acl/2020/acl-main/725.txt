Feature Projection for Improved Text Classification | Qi Qin | in classification , there are usually some good features that are indicative of class labels. for example , in sentiment classification , words like good and nice are indicative of the positive sentiment and words like bad and terrible are indicative of the negative sentiment. however , there are also many common features \( e.g. , words \) that are not indicative of any specific class \( e.g. , voice and screen , which are common to both sentiment classes and are not discriminative for classification \) . although deep learning has made significant progresses in generating discriminative features through its powerful representation learning , we believe there is still room for improvement. in this paper , we propose a novel angle to further improve this representation learning , i.e. , feature projection. this method projects existing features into the orthogonal space of the common features. the resulting projection is thus perpendicular to the common features and more discriminative for classification. we apply this new method to improve cnn , rnn , transformer , and bert based text classification and obtain markedly better results.
