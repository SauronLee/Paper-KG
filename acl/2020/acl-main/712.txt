A Joint Neural Model for Information Extraction with Global Features | Ying Lin | most existing joint neural models for information extraction \( ie \) use local task-specific classifiers to predict labels for individual instances \( e.g. , trigger , relation \) regardless of their interactions. for example , a victim of a die event is likely to be a victim of an attack event in the same sentence. in order to capture such cross-subtask and cross-instance inter-dependencies , we propose a joint neural framework , oneie , that aims to extract the globally optimal ie result as a graph from an input sentence. oneie performs end-to-end ie in four stages: \( 1 \) encoding a given sentence as contextualized word representations; \( 2 \) identifying entity mentions and event triggers as nodes; \( 3 \) computing label scores for all nodes and their pairwise links using local classifiers; \( 4 \) searching for the globally optimal graph with a beam decoder. at the decoding stage , we incorporate global features to capture the cross-subtask and cross-instance interactions. experiments show that adding global features improves the performance of our model and achieves new state of-the-art on all subtasks. in addition , as oneie does not use any language-specific feature , we prove it can be easily applied to new languages or trained in a multilingual manner.
