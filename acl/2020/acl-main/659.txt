From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of Parsing Morphologically-Rich Languages (MRLs)? | Reut Tsarfaty | it has been exactly a decade since the first establishment of spmrl , a research initiative unifying multiple research efforts to address the peculiar challenges of statistical parsing for morphologically-rich languages \( mrls \) . here we reflect on parsing mrls in that decade , highlight the solutions and lessons learned for the architectural , modeling and lexical challenges in the pre-neural era , and argue that similar challenges re-emerge in neural architectures for mrls. we then aim to offer a climax , suggesting that incorporating symbolic ideas proposed in spmrl terms into nowadays neural architectures has the potential to push nlp for mrls to a new level. we sketch a strategies for designing neural models for mrls \( nmrl \) , and showcase preliminary support for these strategies via investigating the task of multi-tagging in hebrew , a morphologically-rich , high-fusion , language.
