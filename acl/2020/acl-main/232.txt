MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning | Jie Lei | generating multi-sentence descriptions for videos is one of the most challenging captioning tasks due to its high requirements for not only visual relevance but also discourse-based coherence across the sentences in the paragraph. towards this goal , we propose a new approach called memory-augmented recurrent transformer \( mart \) , which uses a memory module to augment the transformer architecture. the memory module generates a highly summarized memory state from the video segments and the sentence history so as to help better prediction of the next sentence \( w.r.t. coreference and repetition aspects \) , thus encouraging coherent paragraph generation. extensive experiments , human evaluations , and qualitative analyses on two popular datasets activitynet captions and youcookii show that mart generates more coherent and less repetitive paragraph captions than baseline methods , while maintaining relevance to the input video events.
