Learning Dialog Policies from Weak Demonstrations | Gabriel Gordon-Hall | deep reinforcement learning is a promising approach to training a dialog manager , but current methods struggle with the large state and action spaces of multi-domain dialog systems. building upon deep q-learning from demonstrations \( dqfd \) , an algorithm that scores highly in difficult atari games , we leverage dialog data to guide the agent to successfully respond to a userâ€™s requests. we make progressively fewer assumptions about the data needed , using labeled , reduced-labeled , and even unlabeled data to train expert demonstrators. we introduce reinforced fine-tune learning , an extension to dqfd , enabling us to overcome the domain gap between the datasets and the environment. experiments in a challenging multi-domain dialog system framework validate our approaches , and get high success rates even when trained on out-of-domain data.
