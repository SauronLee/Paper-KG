Improving Disentangled Text Representation Learning with Information-Theoretic Guidance | Pengyu Cheng | learning disentangled representations of natural language is essential for many nlp tasks , e.g. , conditional text generation , style transfer , personalized dialogue systems , etc. similar problems have been studied extensively for other forms of data , such as images and videos. however , the discrete nature of natural language makes the disentangling of textual representations more challenging \( e.g. , the manipulation over the data space cannot be easily achieved \) . inspired by information theory , we propose a novel method that effectively manifests disentangled representations of text , without any supervision on semantics. a new mutual information upper bound is derived and leveraged to measure dependence between style and content. by minimizing this upper bound , the proposed method induces style and content embeddings into two independent low-dimensional spaces. experiments on both conditional text generation and text-style transfer demonstrate the high quality of our disentangled representation in terms of content and style preservation.
