Fine-grained Fact Verification with Kernel Graph Attention Network | Zhenghao Liu | fact verification requires fine-grained natural language inference capability that finds subtle clues to identify the syntactical and semantically correct but not well-supported claims. this paper presents kernel graph attention network \( kgat \) , which conducts more fine-grained fact verification with kernel-based attentions. given a claim and a set of potential evidence sentences that form an evidence graph , kgat introduces node kernels , which better measure the importance of the evidence node , and edge kernels , which conduct fine-grained evidence propagation in the graph , into graph attention networks for more accurate fact verification. kgat achieves a 70.38% fever score and significantly outperforms existing fact verification models on fever , a large-scale benchmark for fact verification. our analyses illustrate that , compared to dot-product attentions , the kernel-based attention concentrates more on relevant evidence sentences and meaningful clues in the evidence graph , which is the main source of kgatâ€™s effectiveness. all source codes of this work are available at https://github.com/thunlp/kernelgat.
