tBERT: Topic Models and BERT Joining Forces for Semantic Similarity Detection | Nicole Peinelt | semantic similarity detection is a fundamental task in natural language understanding. adding topic information has been useful for previous feature-engineered semantic similarity models as well as neural models for other tasks. there is currently no standard way of combining topics with pretrained contextual representations such as bert. we propose a novel topic-informed bert-based architecture for pairwise semantic similarity detection and show that our model improves performance over strong neural baselines across a variety of english language datasets. we find that the addition of topics to bert helps particularly with resolving domain-specific cases.
