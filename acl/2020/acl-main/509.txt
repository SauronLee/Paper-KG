Cross-Lingual Unsupervised Sentiment Classification with Multi-View Transfer Learning | Hongliang Fei | recent neural network models have achieved impressive performance on sentiment classification in english as well as other languages. their success heavily depends on the availability of a large amount of labeled data or parallel corpus. in this paper , we investigate an extreme scenario of cross-lingual sentiment classification , in which the low-resource language does not have any labels or parallel corpus. we propose an unsupervised cross-lingual sentiment classification model named multi-view encoder-classifier \( mvec \) that leverages an unsupervised machine translation \( umt \) system and a language discriminator. unlike previous language model \( lm \) based fine-tuning approaches that adjust parameters solely based on the classification error on training data , we employ the encoder-decoder framework of a umt as a regularization component on the shared network parameters. in particular , the cross-lingual encoder of our model learns a shared representation , which is effective for both reconstructing input sentences of two languages and generating more representative views from the input for classification. extensive experiments on five language pairs verify that our model significantly outperforms other models for 8/11 sentiment classification tasks.
