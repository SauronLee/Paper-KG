BiRRE: Learning Bidirectional Residual Relation Embeddings for Supervised Hypernymy Detection | Chengyu Wang | the hypernymy detection task has been addressed under various frameworks. previously , the design of unsupervised hypernymy scores has been extensively studied. in contrast , supervised classifiers , especially distributional models , leverage the global contexts of terms to make predictions , but are more likely to suffer from “lexical memorization”. in this work , we revisit supervised distributional models for hypernymy detection. rather than taking embeddings of two terms as classification inputs , we introduce a representation learning framework named bidirectional residual relation embeddings \( birre \) . in this model , a term pair is represented by a birre vector as features for hypernymy classification , which models the possibility of a term being mapped to another in the embedding space by hypernymy relations. a latent projection model with negative regularization \( lpmnr \) is proposed to simulate how hypernyms and hyponyms are generated by neural language models , and to generate birre vectors based on bidirectional residuals of projections. experiments verify birre outperforms strong baselines over various evaluation frameworks.
