Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder | Daya Guo | generating inferential texts about an event in different perspectives requires reasoning over different contexts that the event occurs. existing works usually ignore the context that is not explicitly provided , resulting in a context-independent semantic representation that struggles to support the generation. to address this , we propose an approach that automatically finds evidence for an event from a large text corpus , and leverages the evidence to guide the generation of inferential texts. our approach works in an encoderdecoder manner and is equipped with vector quantised-variational autoencoder , where the encoder outputs representations from a distribution over discrete variables. such discrete representations enable automatically selecting relevant evidence , which not only facilitates evidence-aware generation , but also provides a natural way to uncover rationales behind the generation. our approach provides state-of-the-art performance on both event2mind and atomic datasets. more importantly , we find that with discrete representations , our model selectively uses evidence to generate different inferential texts.
