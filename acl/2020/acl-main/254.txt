Breaking Through the 80% Glass Ceiling: Raising the State of the Art in Word Sense Disambiguation by Incorporating Knowledge Graph Information | Michele Bevilacqua | neural architectures are the current state of the art in word sense disambiguation \( wsd \) . however , they make limited use of the vast amount of relational information encoded in lexical knowledge bases \( lkb \) . we present enhanced wsd integrating synset embeddings and relations \( ewiser \) , a neural supervised architecture that is able to tap into this wealth of knowledge by embedding information from the lkb graph within the neural architecture , and to exploit pretrained synset embeddings , enabling the network to predict synsets that are not in the training set. as a result , we set a new state of the art on almost all the evaluation settings considered , also breaking through , for the first time , the 80% ceiling on the concatenation of all the standard all-words english wsd evaluation benchmarks. on multilingual all-words wsd , we report state-of-the-art results by training on nothing but english.
