Cross-Linguistic Syntactic Evaluation of Word Prediction Models | Aaron Mueller | a range of studies have concluded that neural word prediction models can distinguish grammatical from ungrammatical sentences with high accuracy. however , these studies are based primarily on monolingual evidence from english. to investigate how these modelsâ€™ ability to learn syntax varies by language , we introduce clams \( cross-linguistic assessment of models on syntax \) , a syntactic evaluation suite for monolingual and multilingual models. clams includes subject-verb agreement challenge sets for english , french , german , hebrew and russian , generated from grammars we develop. we use clams to evaluate lstm language models as well as monolingual and multilingual bert. across languages , monolingual lstms achieved high accuracy on dependencies without attractors , and generally poor accuracy on agreement across object relative clauses. on other constructions , agreement accuracy was generally higher in languages with richer morphology. multilingual models generally underperformed monolingual models. multilingual bert showed high syntactic accuracy on english , but noticeable deficiencies in other languages.
