CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning | Alessandro Suglia | approaches to grounded language learning are commonly focused on a single task-based final performance measure which may not depend on desirable properties of the learned hidden representations , such as their ability to predict object attributes or generalize to unseen situations. to remedy this , we present grolla , an evaluation framework for grounded language learning with attributes based on three sub-tasks: 1 \) goal-oriented evaluation; 2 \) object attribute prediction evaluation; and 3 \) zero-shot evaluation. we also propose a new dataset compguesswhat \? ! as an instance of this framework for evaluating the quality of learned neural representations , in particular with respect to attribute grounding. to this end , we extend the original guesswhat \? ! dataset by including a semantic layer on top of the perceptual one. specifically , we enrich the visualgenome scene graphs associated with the guesswhat \? ! images with several attributes from resources such as visa and imsitu. we then compare several hidden state representations from current state-of-the-art approaches to grounded language learning. by using diagnostic classifiers , we show that current modelsâ€™ learned representations are not expressive enough to encode object attributes \( average f1 of 44.27 \) . in addition , they do not learn strategies nor representations that are robust enough to perform well when novel scenes or objects are involved in gameplay \( zero-shot best accuracy 50.06% \) .
