Sentence Meta-Embeddings for Unsupervised Semantic Textual Similarity | Nina Poerner | we address the task of unsupervised semantic textual similarity \( sts \) by ensembling diverse pre-trained sentence encoders into sentence meta-embeddings. we apply , extend and evaluate different meta-embedding methods from the word embedding literature at the sentence level , including dimensionality reduction \( yin and schütze , 2016 \) , generalized canonical correlation analysis \( rastogi et al. , 2015 \) and cross-view auto-encoders \( bollegala and bao , 2018 \) . our sentence meta-embeddings set a new unsupervised state of the art \( sota \) on the sts benchmark and on the sts12-sts16 datasets , with gains of between 3.7% and 6.4% pearson’s r over single-source systems.
