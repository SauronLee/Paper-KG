Syntactic Data Augmentation Increases Robustness to Inference Heuristics | Junghyun Min | pretrained neural models such as bert , when fine-tuned to perform natural language inference \( nli \) , often show high accuracy on standard datasets , but display a surprising lack of sensitivity to word order on controlled challenge sets. we hypothesize that this issue is not primarily caused by the pretrained model’s limitations , but rather by the paucity of crowdsourced nli examples that might convey the importance of syntactic structure at the fine-tuning stage. we explore several methods to augment standard training sets with syntactically informative examples , generated by applying syntactic transformations to sentences from the mnli corpus. the best-performing augmentation method , subject/object inversion , improved bert’s accuracy on controlled examples that diagnose sensitivity to word order from 0.28 to 0.73 , without affecting performance on the mnli test set. this improvement generalized beyond the particular construction used for data augmentation , suggesting that augmentation causes bert to recruit abstract syntactic representations.
