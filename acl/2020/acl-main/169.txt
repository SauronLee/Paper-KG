BPE-Dropout: Simple and Effective Subword Regularization | Ivan Provilkov | subword segmentation is widely used to address the open vocabulary problem in machine translation. the dominant approach to subword segmentation is byte pair encoding \( bpe \) , which keeps the most frequent words intact while splitting the rare ones into multiple tokens. while multiple segmentations are possible even with the same vocabulary , bpe splits words into unique sequences; this may prevent a model from better learning the compositionality of words and being robust to segmentation errors. so far , the only way to overcome this bpe imperfection , its deterministic nature , was to create another subword segmentation algorithm \( kudo , 2018 \) . in contrast , we show that bpe itself incorporates the ability to produce multiple segmentations of the same word. we introduce bpe-dropout - simple and effective subword regularization method based on and compatible with conventional bpe. it stochastically corrupts the segmentation procedure of bpe , which leads to producing multiple segmentations within the same fixed bpe framework. using bpe-dropout during training and the standard bpe during inference improves translation quality up to 2.3 bleu compared to bpe and up to 0.9 bleu compared to the previous subword regularization.
