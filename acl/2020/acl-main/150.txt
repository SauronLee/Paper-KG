On the Limitations of Cross-lingual Encoders as Exposed by Reference-Free Machine Translation Evaluation | Wei Zhao | evaluation of cross-lingual encoders is usually performed either via zero-shot cross-lingual transfer in supervised downstream tasks or via unsupervised cross-lingual textual similarity. in this paper , we concern ourselves with reference-free machine translation \( mt \) evaluation where we directly compare source texts to \( sometimes low-quality \) system translations , which represents a natural adversarial setup for multilingual encoders. reference-free evaluation holds the promise of web-scale comparison of mt systems. we systematically investigate a range of metrics based on state-of-the-art cross-lingual semantic representations obtained with pretrained m-bert and laser. we find that they perform poorly as semantic encoders for reference-free mt evaluation and identify their two key limitations , namely , \( a \) a semantic mismatch between representations of mutual translations and , more prominently , \( b \) the inability to punish “translationese” , i.e. , low-quality literal translations. we propose two partial remedies: \( 1 \) post-hoc re-alignment of the vector spaces and \( 2 \) coupling of semantic-similarity based metrics with target-side language modeling. in segment-level mt evaluation , our best metric surpasses reference-based bleu by 5.7 correlation points.
