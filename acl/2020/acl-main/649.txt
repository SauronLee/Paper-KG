Semi-supervised Contextual Historical Text Normalization | Peter Makarov | historical text normalization , the task of mapping historical word forms to their modern counterparts , has recently attracted a lot of interest \( bollmann , 2019; tang et al. , 2018; lusetti et al. , 2018; bollmann et al. , 2018;robertson and goldwater , 2018; bollmannet al. , 2017; korchagina , 2017 \) . yet , virtually all approaches suffer from the two limitations: 1 \) they consider a fully supervised setup , often with impractically large manually normalized datasets; 2 \) normalization happens on words in isolation. by utilizing a simple generative normalization model and obtaining powerful contextualization from the target-side language model , we train accurate models with unlabeled historical data. in realistic training scenarios , our approach often leads to reduction in manually normalized data at the same accuracy levels.
