Modelling Context and Syntactical Features for Aspect-based Sentiment Analysis | Minh Hieu Phan | the aspect-based sentiment analysis \( absa \) consists of two conceptual tasks , namely an aspect extraction and an aspect sentiment classification. rather than considering the tasks separately , we build an end-to-end absa solution. previous works in absa tasks did not fully leverage the importance of syntactical information. hence , the aspect extraction model often failed to detect the boundaries of multi-word aspect terms. on the other hand , the aspect sentiment classifier was unable to account for the syntactical correlation between aspect terms and the context words. this paper explores the grammatical aspect of the sentence and employs the self-attention mechanism for syntactical learning. we combine part-of-speech embeddings , dependency-based embeddings and contextualized embeddings \( e.g. bert , roberta \) to enhance the performance of the aspect extractor. we also propose the syntactic relative distance to de-emphasize the adverse effects of unrelated words , having weak syntactic connection with the aspect terms. this increases the accuracy of the aspect sentiment classifier. our solutions outperform the state-of-the-art models on semeval-2014 dataset in both two subtasks.
