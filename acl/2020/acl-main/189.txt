ExpBERT: Representation Engineering with Natural Language Explanations | Shikhar Murty | suppose we want to specify the inductive bias that married couples typically go on honeymoons for the task of extracting pairs of spouses from text. in this paper , we allow model developers to specify these types of inductive biases as natural language explanations. we use bert fine-tuned on multinli to “interpret” these explanations with respect to the input sentence , producing explanation-guided representations of the input. across three relation extraction tasks , our method , expbert , matches a bert baseline but with 3–20x less labeled data and improves on the baseline by 3–10 f1 points with the same amount of labeled data.
