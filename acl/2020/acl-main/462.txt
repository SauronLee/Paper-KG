Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data | Emily M. Bender | the success of the large neural language models on many nlp tasks is exciting. however , we find that these successes sometimes lead to hype in which these models are being described as “understanding” language or capturing “meaning”. in this position paper , we argue that a system trained only on form has a priori no way to learn meaning. in keeping with the acl 2020 theme of “taking stock of where we’ve been and where we’re going” , we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.
