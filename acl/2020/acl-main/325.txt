On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation | Chaojun Wang | the standard training algorithm in neural machine translation \( nmt \) suffers from exposure bias , and alternative algorithms have been proposed to mitigate this. however , the practical impact of exposure bias is under debate. in this paper , we link exposure bias to another well-known problem in nmt , namely the tendency to generate hallucinations under domain shift. in experiments on three datasets with multiple test domains , we show that exposure bias is partially to blame for hallucinations , and that training with minimum risk training , which avoids exposure bias , can mitigate this. our analysis explains why exposure bias is more problematic under domain shift , and also links exposure bias to the beam search problem , i.e. performance deterioration with increasing beam size. our results provide a new justification for methods that reduce exposure bias: even if they do not increase performance on in-domain test sets , they can increase model robustness to domain shift.
