Improving Entity Linking through Semantic Reinforced Entity Embeddings | Feng Hou | entity embeddings , which represent different aspects of each entity with a single vector like word embeddings , are a key component of neural entity linking models. existing entity embeddings are learned from canonical wikipedia articles and local contexts surrounding target entities. such entity embeddings are effective , but too distinctive for linking models to learn contextual commonality. we propose a simple yet effective method , fgs2ee , to inject fine-grained semantic information into entity embeddings to reduce the distinctiveness and facilitate the learning of contextual commonality. fgs2ee first uses the embeddings of semantic type words to generate semantic embeddings , and then combines them with existing entity embeddings through linear aggregation. extensive experiments show the effectiveness of such embeddings. based on our entity embeddings , we achieved new sate-of-the-art performance on entity linking.
