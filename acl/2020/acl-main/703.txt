BLEURT: Learning Robust Metrics for Text Generation | Thibault Sellam | text generation has made significant advances in the last few years. yet , evaluation metrics have lagged behind , as the most popular choices \( e.g. , bleu and rouge \) may correlate poorly with human judgment. we propose bleurt , a learned evaluation metric for english based on bert. bleurt can model human judgment with a few thousand possibly biased training examples. a key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. bleurt provides state-of-the-art results on the last three years of the wmt metrics shared task and the webnlg data set. in contrast to a vanilla bert-based approach , it yields superior results even when the training data is scarce and out-of-distribution.
