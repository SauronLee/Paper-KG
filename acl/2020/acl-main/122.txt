Improving Truthfulness of Headline Generation | Kazuki Matsumaru | most studies on abstractive summarization report rouge scores between system and reference summaries. however , we have a concern about the truthfulness of generated summaries: whether all facts of a generated summary are mentioned in the source text. this paper explores improving the truthfulness in headline generation on two popular datasets. analyzing headlines generated by the state-of-the-art encoder-decoder model , we show that the model sometimes generates untruthful headlines. we conjecture that one of the reasons lies in untruthful supervision data used for training the model. in order to quantify the truthfulness of article-headline pairs , we consider the textual entailment of whether an article entails its headline. after confirming quite a few untruthful instances in the datasets , this study hypothesizes that removing untruthful instances from the supervision data may remedy the problem of the untruthful behaviors of the model. building a binary classifier that predicts an entailment relation between an article and its headline , we filter out untruthful instances from the supervision data. experimental results demonstrate that the headline generation model trained on filtered supervision data shows no clear difference in rouge scores but remarkable improvements in automatic and manual evaluations of the generated headlines.
