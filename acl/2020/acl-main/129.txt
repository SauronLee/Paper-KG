MuTual: A Dataset for Multi-Turn Dialogue Reasoning | Leyang Cui | non-task oriented dialogue systems have achieved great success in recent years due to largely accessible conversation data and the development of deep learning techniques. given a context , current systems are able to yield a relevant and fluent response , but sometimes make logical mistakes because of weak reasoning capabilities. to facilitate the conversation reasoning research , we introduce mutual , a novel dataset for multi-turn dialogue reasoning , consisting of 8 , 860 manually annotated dialogues based on chinese student english listening comprehension exams. compared to previous benchmarks for non-task oriented dialogue systems , mutual is much more challenging since it requires a model that be able to handle various reasoning problems. empirical results show that state-of-the-art methods only reach 71% , which is far behind human performance of 94% , indicating that there is ample room for improving reasoning ability.
