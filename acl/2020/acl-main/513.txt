A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks | Nastaran Babanejad | affective tasks such as sentiment analysis , emotion classification , and sarcasm detection have been popular in recent years due to an abundance of user-generated data , accurate computational linguistic models , and a broad range of relevant applications in various domains. at the same time , many studies have highlighted the importance of text preprocessing , as an integral step to any natural language processing prediction model and downstream task. while preprocessing in affective systems is well-studied , preprocessing in word vector-based models applied to affective systems , is not. to address this limitation , we conduct a comprehensive analysis of the role of preprocessing techniques in affective analysis based on word vector models. our analysis is the first of its kind and provides useful insights of the importance of each preprocessing technique when applied at the training phase , commonly ignored in pretrained word vector models , and/or at the downstream task phase.
