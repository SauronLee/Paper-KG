SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions | Mao Ye | state-of-the-art nlp models can often be fooled by human-unaware transformations such as synonymous word substitution. for security reasons , it is of critical importance to develop models with certified robustness that can provably guarantee that the prediction is can not be altered by any possible synonymous word substitution. in this work , we propose a certified robust method based on a new randomized smoothing technique , which constructs a stochastic ensemble by applying random word substitutions on the input sentences , and leverage the statistical properties of the ensemble to provably certify the robustness. our method is simple and structure-free in that it only requires the black-box queries of the model outputs , and hence can be applied to any pre-trained models \( such as bert \) and any types of models \( world-level or subword-level \) . our method significantly outperforms recent state-of-the-art methods for certified robustness on both imdb and amazon text classification tasks. to the best of our knowledge , we are the first work to achieve certified robustness on large systems such as bert with practically meaningful certified accuracy.
