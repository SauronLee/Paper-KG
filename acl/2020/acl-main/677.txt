Temporal Common Sense Acquisition with Minimal Supervision | Ben Zhou | temporal common sense \( e.g. , duration and frequency of events \) is crucial for understanding natural language. however , its acquisition is challenging , partly because such information is often not expressed explicitly in text , and human annotation on such concepts is costly. this work proposes a novel sequence modeling approach that exploits explicit and implicit mentions of temporal common sense , extracted from a large corpus , to build tacolm , a temporal common sense language model. our method is shown to give quality predictions of various dimensions of temporal common sense \( on udst and a newly collected dataset from realnews \) . it also produces representations of events for relevant tasks such as duration comparison , parent-child relations , event coreference and temporal qa \( on timebank , hieve and mctaco \) that are better than using the standard bert. thus , it will be an important component of temporal nlp.
