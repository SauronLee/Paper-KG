Adversarial NLI: A New Benchmark for Natural Language Understanding | Yixin Nie | we introduce a new large-scale nli benchmark dataset , collected via an iterative , adversarial human-and-model-in-the-loop procedure. we show that training models on this new dataset leads to state-of-the-art performance on a variety of popular nli benchmarks , while posing a more difficult challenge with its new test set. our analysis sheds light on the shortcomings of current state-of-the-art models , and shows that non-expert annotators are successful at finding their weaknesses. the data collection method can be applied in a never-ending learning scenario , becoming a moving target for nlu , rather than a static benchmark that will quickly saturate.
