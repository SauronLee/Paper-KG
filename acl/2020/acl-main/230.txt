Learning to Segment Actions from Observation and Narration | Daniel Fried | we apply a generative segmental model of task structure , guided by narration , to action segmentation in video. we focus on unsupervised and weakly-supervised settings where no action labels are known during training. despite its simplicity , our model performs competitively with previous work on a dataset of naturalistic instructional videos. our model allows us to vary the sources of supervision used in training , and we find that both task structure and narrative language provide large benefits in segmentation quality.
