To Test Machine Comprehension, Start by Defining Comprehension | Jesse Dunietz | many tasks aim to measure machine reading comprehension \( mrc \) , often focusing on question types presumed to be difficult. rarely , however , do task designers start by considering what systems should in fact comprehend. in this paper we make two key contributions. first , we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. second , we present a detailed definition of comprehension—a “template of understanding”—for a widely useful class of texts , namely short narratives. we then conduct an experiment that strongly suggests existing systems are not up to the task of narrative understanding as we define it.
