Rationalizing Text Matching: Learning Sparse Alignments via Optimal Transport | Kyle Swanson | selecting input features of top relevance has become a popular method for building self-explaining models. in this work , we extend this selective rationalization approach to text matching , where the goal is to jointly select and align text pieces , such as tokens or sentences , as a justification for the downstream prediction. our approach employs optimal transport \( ot \) to find a minimal cost alignment between the inputs. however , directly applying ot often produces dense and therefore uninterpretable alignments. to overcome this limitation , we introduce novel constrained variants of the ot problem that result in highly sparse alignments with controllable sparsity. our model is end-to-end differentiable using the sinkhorn algorithm for ot and can be trained without any alignment annotations. we evaluate our model on the stackexchange , multinews , e-snli , and multirc datasets. our model achieves very sparse rationale selections with high fidelity while preserving prediction accuracy compared to strong attention baseline models.
