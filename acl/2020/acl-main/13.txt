TransS-Driven Joint Learning Architecture for Implicit Discourse Relation Recognition | Ruifang He | implicit discourse relation recognition is a challenging task due to the lack of connectives as strong linguistic clues. previous methods primarily encode two arguments separately or extract the specific interaction patterns for the task , which have not fully exploited the annotated relation signal. therefore , we propose a novel transs-driven joint learning architecture to address the issues. specifically , based on the multi-level encoder , we 1 \) translate discourse relations in low-dimensional embedding space \( called transs \) , which could mine the latent geometric structure information of argument-relation instances; 2 \) further exploit the semantic features of arguments to assist discourse understanding; 3 \) jointly learn 1 \) and 2 \) to mutually reinforce each other to obtain the better argument representations , so as to improve the performance of the task. extensive experimental results on the penn discourse treebank \( pdtb \) show that our model achieves competitive results against several state-of-the-art systems.
