Phone Features Improve Speech Translation | Elizabeth Salesky | end-to-end models for speech translation \( st \) more tightly couple speech recognition \( asr \) and machine translation \( mt \) than a traditional cascade of separate asr and mt models , with simpler model architectures and the potential for reduced error propagation. their performance is often assumed to be superior , though in many conditions this is not yet the case. we compare cascaded and end-to-end models across high , medium , and low-resource conditions , and show that cascades remain stronger baselines. further , we introduce two methods to incorporate phone features into st models. we show that these features improve both architectures , closing the gap between end-to-end models and cascades , and outperforming previous academic work â€“ by up to 9 bleu on our low-resource setting.
