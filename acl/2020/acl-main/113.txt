Multimodal Quality Estimation for Machine Translation | Shu Okabe | we propose approaches to quality estimation \( qe \) for machine translation that explore both text and visual modalities for multimodal qe. we compare various multimodality integration and fusion strategies. for both sentence-level and document-level predictions , we show that state-of-the-art neural and feature-based qe frameworks obtain better results when using the additional modality.
