Multi-Cell Compositional LSTM for NER Domain Adaptation | Chen Jia | cross-domain ner is a challenging yet practical problem. entity mentions can be highly different across domains. however , the correlations between entity types can be relatively more stable across domains. we investigate a multi-cell compositional lstm structure for multi-task learning , modeling each entity type using a separate cell state. with the help of entity typed units , cross-domain knowledge transfer can be made in an entity type level. theoretically , the resulting distinct feature distributions for each entity type make it more powerful for cross-domain transfer. empirically , experiments on four few-shot and zero-shot datasets show our method significantly outperforms a series of multi-task learning methods and achieves the best results.
