Not All Claims are Created Equal: Choosing the Right Statistical Approach to Assess Hypotheses | Erfan Sadeqi Azer | empirical research in natural language processing \( nlp \) has adopted a narrow set of principles for assessing hypotheses , relying mainly on p-value computation , which suffers from several known issues. while alternative proposals have been well-debated and adopted in other fields , they remain rarely discussed or used within the nlp community. we address this gap by contrasting various hypothesis assessment techniques , especially those not commonly used in the field \( such as evaluations based on bayesian inference \) . since these statistical techniques differ in the hypotheses they can support , we argue that practitioners should first decide their target hypothesis before choosing an assessment method. this is crucial because common fallacies , misconceptions , and misinterpretation surrounding hypothesis assessment methods often stem from a discrepancy between what one would like to claim versus what the method used actually assesses. our survey reveals that these issues are omnipresent in the nlp research community. as a step forward , we provide best practices and guidelines tailored to nlp research , as well as an easy-to-use package for bayesian assessment of hypotheses , complementing existing tools.
