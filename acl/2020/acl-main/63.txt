USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation | Shikib Mehri | the lack of meaningful automatic evaluation metrics for dialog has impeded open-domain dialog research. standard language generation metrics have been shown to be ineffective for evaluating dialog models. to this end , this paper presents usr , an unsupervised and reference-free evaluation metric for dialog. usr is a reference-free metric that trains unsupervised models to measure several desirable qualities of dialog. usr is shown to strongly correlate with human judgment on both topical-chat \( turn-level: 0.42 , system-level: 1.0 \) and personachat \( turn-level: 0.48 and system-level: 1.0 \) . usr additionally produces interpretable measures for several desirable properties of dialog.
