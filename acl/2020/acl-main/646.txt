Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection | Shauli Ravfogel | the ability to control for the kinds of information encoded in neural representation has a variety of use cases , especially in light of the challenge of interpreting these models. we present iterative null-space projection \( inlp \) , a novel method for removing information from neural representations. our method is based on repeated training of linear classifiers that predict a certain property we aim to remove , followed by projection of the representations on their null-space. by doing so , the classifiers become oblivious to that target property , making it hard to linearly separate the data according to it. while applicable for multiple uses , we evaluate our method on bias and fairness use-cases , and show that our method is able to mitigate bias in word embeddings , as well as to increase fairness in a setting of multi-class classification.
