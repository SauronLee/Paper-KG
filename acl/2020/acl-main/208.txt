Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction | Samuel Broscheit | open information extraction systems extract \( “subject text” , “relation text” , “object text” \) triples from raw text. some triples are textual versions of facts , i.e. , non-canonicalized mentions of entities and relations. in this paper , we investigate whether it is possible to infer new facts directly from the open knowledge graph without any canonicalization or any supervision from curated knowledge. for this purpose , we propose the open link prediction task , i.e. , predicting test facts by completing \( “subject text” , “relation text” , \? \) questions. an evaluation in such a setup raises the question if a correct prediction is actually a new fact that was induced by reasoning over the open knowledge graph or if it can be trivially explained. for example , facts can appear in different paraphrased textual variants , which can lead to test leakage. to this end , we propose an evaluation protocol and a methodology for creating the open link prediction benchmark olpbench. we performed experiments with a prototypical knowledge graph embedding model for openlink prediction. while the task is very challenging , our results suggests that it is possible to predict genuinely new facts , which can not be trivially explained.
