SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics | Da Yin | we propose sentibert , a variant of bert that effectively captures compositional sentiment semantics. the model incorporates contextualized representation with binary constituency parse tree to capture semantic composition. comprehensive experiments demonstrate that sentibert achieves competitive performance on phrase-level sentiment classification. we further demonstrate that the sentiment composition learned from the phrase-level annotations on sst can be transferred to other sentiment analysis tasks as well as related tasks , such as emotion classification tasks. moreover , we conduct ablation studies and design visualization methods to understand sentibert. we show that sentibert is better than baseline approaches in capturing negation and the contrastive relation and model the compositional sentiment semantics.
