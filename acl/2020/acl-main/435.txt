Shaping Visual Representations with Language for Few-Shot Classification | Jesse Mu | by describing the features and abstractions of our world , language is a crucial tool for human learning and a promising source of supervision for machine learning models. we use language to improve few-shot visual classification in the underexplored scenario where natural language task descriptions are available during training , but unavailable for novel tasks at test time. existing models for this setting sample new descriptions at test time and use those to classify images. instead , we propose language-shaped learning \( lsl \) , an end-to-end model that regularizes visual representations to predict language. lsl is conceptually simpler , more data efficient , and outperforms baselines in two challenging few-shot domains.
