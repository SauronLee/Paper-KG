Improving Image Captioning Evaluation by Considering Inter References Variance | Yanzhi Yi | evaluating image captions is very challenging partially due to the fact that there are multiple correct captions for every single image. most of the existing one-to-one metrics operate by penalizing mismatches between reference and generative caption without considering the intrinsic variance between ground truth captions. it usually leads to over-penalization and thus a bad correlation to human judgment. recently , the latest one-to-one metric bertscore can achieve high human correlation in system-level tasks while some issues can be fixed for better performance. in this paper , we propose a novel metric based on bertscore that could handle such a challenge and extend bertscore with a few new features appropriately for image captioning evaluation. the experimental results show that our metric achieves state-of-the-art human judgment correlation.
