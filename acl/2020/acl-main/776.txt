SeqVAT: Virtual Adversarial Training for Semi-Supervised Sequence Labeling | Luoxin Chen | virtual adversarial training \( vat \) is a powerful technique to improve model robustness in both supervised and semi-supervised settings. it is effective and can be easily adopted on lots of image classification and text classification tasks. however , its benefits to sequence labeling tasks such as named entity recognition \( ner \) have not been shown as significant , mostly , because the previous approach can not combine vat with the conditional random field \( crf \) . crf can significantly boost accuracy for sequence models by putting constraints on label transitions , which makes it an essential component in most state-of-the-art sequence labeling model architectures. in this paper , we propose seqvat , a method which naturally applies vat to sequence labeling models with crf. empirical studies show that seqvat not only significantly improves the sequence labeling performance over baselines under supervised settings , but also outperforms state-of-the-art approaches under semi-supervised settings.
