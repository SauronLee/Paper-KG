Simple Compounded-Label Training for Fact Extraction and Verification | Yixin Nie | automatic fact checking is an important task motivated by the need for detecting and preventing the spread of misinformation across the web. the recently released fever challenge provides a benchmark task that assesses systemsâ€™ capability for both the retrieval of required evidence and the identification of authentic claims. previous approaches share a similar pipeline training paradigm that decomposes the task into three subtasks , with each component built and trained separately. although achieving acceptable scores , these methods induce difficulty for practical application development due to unnecessary complexity and expensive computation. in this paper , we explore the potential of simplifying the system design and reducing training computation by proposing a joint training setup in which a single sequence matching model is trained with compounded labels that give supervision for both sentence selection and claim verification subtasks , eliminating the duplicate computation that occurs when models are designed and trained separately. empirical results on fever indicate that our method: \( 1 \) outperforms the typical multi-task learning approach , and \( 2 \) gets comparable results to top performing systems with a much simpler training setup and less training computation \( in terms of the amount of data consumed and the number of model parameters \) , facilitating future works on the automatic fact checking task and its practical usage.
