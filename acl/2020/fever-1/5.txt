Maintaining Quality in FEVER Annotation | Leon Derczynski | we propose two measures for measuring the quality of constructed claims in the fever task. annotating data for this task involves the creation of supporting and refuting claims over a set of evidence. automatic annotation processes often leave superficial patterns in data , which learning systems can detect instead of performing the underlying task. humans also can leave these superficial patterns , either voluntarily or involuntarily \( due to e.g. fatigue \) . the two measures introduced attempt to detect the impact of these superficial patterns. one is a new information-theoretic and distributionality based measure ,
