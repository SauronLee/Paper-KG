Transformer-based Context-aware Sarcasm Detection in Conversation Threads from Social Media | Xiangjue Dong | we present a transformer-based sarcasm detection model that accounts for the context from the entire conversation thread for more robust predictions. our model uses deep transformer layers to perform multi-head attentions among the target utterance and the relevant context in the thread. the context-aware models are evaluated on two datasets from social media , twitter and reddit , and show 3.1% and 7.0% improvements over their baselines. our best models give the f1-scores of 79.0% and 75.0% for the twitter and reddit datasets respectively , becoming one of the highest performing systems among 36 participants in this shared task.
