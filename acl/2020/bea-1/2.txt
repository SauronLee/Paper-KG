Multiple Instance Learning for Content Feedback Localization without Annotation | Scott Hellman | automated essay scoring \( aes \) can be used to automatically generate holistic scores with reliability comparable to human scoring. in addition , aes systems can provide formative feedback to learners , typically at the essay level. in contrast , we are interested in providing feedback specialized to the content of the essay , and specifically for the content areas required by the rubric. a key objective is that the feedback should be localized alongside the relevant essay text. an important step in this process is determining where in the essay the rubric designated points and topics are discussed. a natural approach to this task is to train a classifier using manually annotated data; however , collecting such data is extremely resource intensive. instead , we propose a method to predict these annotation spans without requiring any labeled annotation data. our approach is to consider aes as a multiple instance learning \( mil \) task. we show that such models can both predict content scores and localize content by leveraging their sentence-level score predictions. this capability arises despite never having access to annotation training data. implications are discussed for improving formative feedback and explainable aes models.
