GECToR â€“ Grammatical Error Correction: Tag, Not Rewrite | Kostiantyn Omelianchuk | in this paper , we present a simple and efficient gec sequence tagger using a transformer encoder. our system is pre-trained on synthetic data and then fine-tuned in two stages: first on errorful corpora , and second on a combination of errorful and error-free parallel corpora. we design custom token-level transformations to map input tokens to target corrections. our best single-model/ensemble gec tagger achieves an f_0.5 of 65.3/66.5 on conll-2014 \( test \) and f_0.5 of 72.4/73.6 on bea-2019 \( test \) . its inference speed is up to 10 times as fast as a transformer-based seq2seq gec system.
