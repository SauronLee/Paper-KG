Should You Fine-Tune BERT for Automated Essay Scoring? | Elijah Mayfield | most natural language processing research now recommends large transformer-based models with fine-tuning for supervised classification tasks; older strategies like bag-of-words features and linear models have fallen out of favor. here we investigate whether , in automated essay scoring \( aes \) research , deep neural models are an appropriate technological choice. we find that fine-tuning bert produces similar performance to classical models at significant additional cost. we argue that while state-of-the-art strategies do match existing best results , they come with opportunity costs in computational resources. we conclude with a review of promising areas for research on student essays where the unique characteristics of transformers may provide benefits over classical methods to justify the costs.
