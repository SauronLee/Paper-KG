Adversarial Training for Commonsense Inference | Lis Pereira | we apply small perturbations to word embeddings and minimize the resultant adversarial risk to regularize the model. we exploit a novel combination of two different approaches to estimate these perturbations: 1 \) using the true label and 2 \) using the model prediction. without relying on any human-crafted features , knowledge bases , or additional datasets other than the target datasets , our model boosts the fine-tuning performance of roberta , achieving competitive results on multiple reading comprehension datasets that require commonsense inference.
