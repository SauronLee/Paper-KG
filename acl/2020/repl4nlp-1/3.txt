Word Embeddings as Tuples of Feature Probabilities | Siddharth Bhat | in this paper , we provide an alternate perspective on word representations , by reinterpreting the dimensions of the vector space of a word embedding as a collection of features. in this reinterpretation , every component of the word vector is normalized against all the word vectors in the vocabulary. this idea now allows us to view each vector as an
