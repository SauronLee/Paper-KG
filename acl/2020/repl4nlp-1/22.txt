Supertagging with CCG primitives | Aditya Bhargava | in ccg and other highly lexicalized grammars , supertagging a sentenceâ€™s words with their lexical categories is a critical step for efficient parsing. because of the high degree of lexicalization in these grammars , the lexical categories can be very complex. existing approaches to supervised ccg supertagging treat the categories as atomic units , even when the categories are not simple; when they encounter words with categories unseen during training , their guesses are accordingly unsophisticated. in this paper , we make use of the primitives and operators that constitute the lexical categories of categorial grammars. instead of opaque labels , we treat lexical categories themselves as linear sequences. we present an lstm-based model that replaces standard word-level classification with prediction of a sequence of primitives , similarly to lstm decoders. our model obtains state-of-the-art word accuracy for single-task english ccg supertagging , increases parser coverage and f1 , and is able to produce novel categories. analysis shows a synergistic effect between this decomposed view and incorporation of prediction history.
