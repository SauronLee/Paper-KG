Examination and Extension of Strategies for Improving Personalized Language Modeling via Interpolation | Liqun Shao | in this paper , we detail novel strategies for interpolating personalized language models and methods to handle out-of-vocabulary \( oov \) tokens to improve personalized language models. using publicly available data from reddit , we demonstrate improvements in offline metrics at the user level by interpolating a global lstm-based authoring model with a user-personalized n-gram model. by optimizing this approach with a back-off to uniform oov penalty and the interpolation coefficient , we observe that over 80% of users receive a lift in perplexity , with an average of 5.4% in perplexity lift per user. in doing this research we extend previous work in building nlis and improve the robustness of metrics for downstream tasks.
