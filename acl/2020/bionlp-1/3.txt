Improving Biomedical Analogical Retrieval with Embedding of Structural Dependencies | Amandalynne Paullada | inferring the nature of the relationships between biomedical entities from text is an important problem due to the difficulty of maintaining human-curated knowledge bases in rapidly evolving fields. neural word embeddings have earned attention for an apparent ability to encode relational information. however , word embedding models that disregard syntax during training are limited in their ability to encode the structural relationships fundamental to cognitive theories of analogy. in this paper , we demonstrate the utility of encoding dependency structure in word embeddings in a model we call embedding of structural dependencies \( esd \) as a way to represent biomedical relationships in two analogical retrieval tasks: a relationship retrieval \( rr \) task , and a literature-based discovery \( lbd \) task meant to hypothesize plausible relationships between pairs of entities unseen in training. we compare our model to skip-gram with negative sampling \( sgns \) , using 19 databases of biomedical relationships as our evaluation data , with improvements in performance on 17 \( lbd \) and 18 \( rr \) of these sets. these results suggest embeddings encoding dependency path information are of value for biomedical analogy retrieval.
