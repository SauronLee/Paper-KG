Sequence-to-Set Semantic Tagging for Complex Query Reformulation and Automated Text Categorization in Biomedical IR using Self-Attention | Manirupa Das | novel contexts , comprising a set of terms referring to one or more concepts , may often arise in complex querying scenarios such as in evidence-based medicine \( ebm \) involving biomedical literature. these may not explicitly refer to entities or canonical concept forms occurring in a fact-based knowledge source , e.g. the umls ontology. moreover , hidden associations between related concepts meaningful in the current context , may not exist within a single document , but across documents in the collection. predicting semantic concept tags of documents can therefore serve to associate documents related in unseen contexts , or categorize them , in information filtering or retrieval scenarios. thus , inspired by the success of sequence-to-sequence neural models , we develop a novel sequence-to-set framework with attention , for learning document representations in a unique unsupervised setting , using no human-annotated document labels or external knowledge resources and only corpus-derived term statistics to drive the training , that can effect term transfer within a corpus for semantically tagging a large collection of documents. our sequence-to-set modeling approach to predict semantic tags , gives to the best of our knowledge , the state-of-the-art for both , an unsupervised query expansion \( qe \) task for the trec cds 2016 challenge dataset when evaluated on an okapi bm25â€“based document retrieval system; and also over the mltm system baseline baseline \( soleimani and miller , 2016 \) , for both supervised and semi-supervised multi-label prediction tasks on the del.icio.us and ohsumed datasets. we make our code and data publicly available.
