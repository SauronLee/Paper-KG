exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models | Benjamin Hoover | large transformer-based language models can route and reshape complex information via their multi-headed attention mechanism. although the attention never receives explicit supervision , it can exhibit recognizable patterns following linguistic or positional information. analyzing the learned representations and attentions is paramount to furthering our understanding of the inner workings of these models. however , analyses have to catch up with the rapid release of new models and the growing diversity of investigation techniques. to support analysis for a wide variety of models , we introduce exbert , a tool to help humans conduct flexible , interactive investigations and formulate hypotheses for the model-internal reasoning process. exbert provides insights into the meaning of the contextual representations and attention by matching a human-specified input to similar contexts in large annotated datasets. by aggregating the annotations of the matched contexts , exbert can quickly replicate findings from literature and extend them to previously not analyzed models.
