CLIReval: Evaluating Machine Translation as a Cross-Lingual Information Retrieval Task | Shuo Sun | we present clireval , an easy-to-use toolkit for evaluating machine translation \( mt \) with the proxy task of cross-lingual information retrieval \( clir \) . contrary to what the project name might suggest , clireval does not actually require any annotated clir dataset. instead , it automatically transforms translations and references used in mt evaluations into a synthetic clir dataset; it then sets up a standard search engine \( elasticsearch \) and computes various information retrieval metrics \( e.g. , mean average precision \) by treating the translations as documents to be retrieved. the idea is to gauge the quality of mt by its impact on the document translation approach to clir. as a case study , we run clireval on the “metrics shared task” of wmt2019; while this extrinsic metric is not intended to replace popular intrinsic metrics such as bleu , results suggest clireval is competitive in many language pairs in terms of correlation to human judgments of quality. clireval is publicly available at https://github.com/ssun32/clireval.
