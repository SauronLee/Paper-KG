The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding | Xiaodong Liu | we present mt-dnn , an open-source natural language understanding \( nlu \) toolkit that makes it easy for researchers and developers to train customized deep learning models. built upon pytorch and transformers , mt-dnn is designed to facilitate rapid customization for a broad spectrum of nlu tasks , using a variety of objectives \( classification , regression , structured prediction \) and text encoders \( e.g. , rnns , bert , roberta , unilm \) . a unique feature of mt-dnn is its built-in support for robust and transferable learning using the adversarial multi-task learning paradigm. to enable efficient production deployment , mt-dnn supports multi-task knowledge distillation , which can substantially compress a deep neural model without significant performance drop. we demonstrate the effectiveness of mt-dnn on a wide range of nlu applications across general and biomedical domains. the software and pre-trained models will be publicly available at https://github.com/namisan/mt-dnn.
