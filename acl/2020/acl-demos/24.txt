Interactive Task Learning from GUI-Grounded Natural Language Instructions and Demonstrations | Toby Jia-Jun Li | we show sugilite , an intelligent task automation agent that can learn new tasks and relevant associated concepts interactively from the userâ€™s natural language instructions and demonstrations , using the graphical user interfaces \( guis \) of third-party mobile apps. this system provides several interesting features: \( 1 \) it allows users to teach new task procedures and concepts through verbal instructions together with demonstration of the steps of a script using guis; \( 2 \) it supports users in clarifying their intents for demonstrated actions using gui-grounded verbal instructions; \( 3 \) it infers parameters of tasks and their possible values in utterances using the hierarchical structures of the underlying app guis; and \( 4 \) it generalizes taught concepts to different contexts and task domains. we describe the architecture of the sugilite system , explain the design and implementation of its key features , and show a prototype in the form of a conversational assistant on android.
