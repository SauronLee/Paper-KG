Learning to Classify Intents and Slot Labels Given a Handful of Examples | Jason Krone | intent classification \( ic \) and slot filling \( sf \) are core components in most goal-oriented dialogue systems. current ic/sf models perform poorly when the number of training examples per class is small. we propose a new few-shot learning task , few-shot ic/sf , to study and improve the performance of ic and sf models on classes not seen at training time in ultra low resource scenarios. we establish a few-shot ic/sf benchmark by defining few-shot splits for three public ic/sf datasets , atis , top , and snips. we show that two popular few-shot learning algorithms , model agnostic meta learning \( maml \) and prototypical networks , outperform a fine-tuning baseline on this benchmark. prototypical networks achieves significant gains in ic performance on the atis and top datasets , while both prototypical networks and maml outperform the baseline with respect to sf on all three datasets. in addition , we demonstrate that joint training as well as the use of pre-trained language models , elmo and bert in our case , are complementary to these few-shot learning methods and yield further gains.
