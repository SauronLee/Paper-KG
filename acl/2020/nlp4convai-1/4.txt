Efficient Intent Detection with Dual Sentence Encoders | IÃ±igo Casanueva | building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes \( i.e. , in few-shot setups \) . motivated by these requirements , we introduce intent detection methods backed by pretrained dual sentence encoders such as use and convert. we demonstrate the usefulness and wide applicability of the proposed intent detectors , showing that: 1 \) they outperform intent detectors based on fine-tuning the full bert-large model or using bert as a fixed black-box encoder on three diverse intent detection data sets; 2 \) the gains are especially pronounced in few-shot setups \( i.e. , with only 10 or 30 annotated examples per intent \) ; 3 \) our intent detectors can be trained in a matter of minutes on a single cpu; and 4 \) they are stable across different hyperparameter settings. in hope of facilitating and democratizing research focused on intention detection , we release our code , as well as a new challenging single-domain intent detection dataset comprising 13 , 083 annotated examples over 77 intents.
