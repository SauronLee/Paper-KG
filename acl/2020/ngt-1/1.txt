Learning to Generate Multiple Style Transfer Outputs for an Input Sentence | Kevin Lin | text style transfer refers to the task of rephrasing a given text in a different style. while various methods have been proposed to advance the state of the art , they often assume the transfer output follows a delta distribution , and thus their models cannot generate different style transfer results for a given input text. to address the limitation , we propose a one-to-many text style transfer framework. in contrast to prior works that learn a one-to-one mapping that converts an input sentence to one output sentence , our approach learns a one-to-many mapping that can convert an input sentence to multiple different output sentences , while preserving the input content. this is achieved by applying adversarial training with a latent decomposition scheme. specifically , we decompose the latent representation of the input sentence to a style code that captures the language style variation and a content code that encodes the language style-independent content. we then combine the content code with the style code for generating a style transfer output. by combining the same content code with a different style code , we generate a different style transfer output. extensive experimental results with comparisons to several text style transfer approaches on multiple public datasets using a diverse set of performance metrics validate effectiveness of the proposed approach.
