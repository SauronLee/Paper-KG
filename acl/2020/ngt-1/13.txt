Meeting the 2020 Duolingo Challenge on a Shoestring | Tadashi Nomoto | what is given below is a brief description of the two systems , called gfconv and c-vae , which we built in a response to the 2020 duolingo challenge. both are neural models that aim at disrupting a sentence representation the encoder generates with an eye on increasing the diversity of sentences that emerge out of the process. importantly , we decided not to turn to external sources for extra ammunition , curious to know how far we can go while confining ourselves to the data released by duolingo. gfconv works by taking over a pre-trained sequence model , and intercepting the output its encoder produces on its way to the decoder. c-vae is a conditional variational auto-encoder , seeking the diversity by blurring the representation that the encoder derives. experiments on a corpus constructed out of the public dataset from duolingo , containing some 4 million pairs of sentences , found that gfconv is a consistent winner over c-vae though both suffered heavily from a low recall.
