A Deep Reinforced Model for Zero-Shot Cross-Lingual Summarization with Bilingual Semantic Similarity Rewards | Zi-Yi Dou | cross-lingual text summarization aims at generating a document summary in one language given input in another language. it is a practically important but under-explored task , primarily due to the dearth of available data. existing methods resort to machine translation to synthesize training data , but such pipeline approaches suffer from error propagation. in this work , we propose an end-to-end cross-lingual text summarization model. the model uses reinforcement learning to directly optimize a bilingual semantic similarity metric between the summaries generated in a target language and gold summaries in a source language. we also introduce techniques to pre-train the model leveraging monolingual summarization and machine translation objectives. experimental results in both english–chinese and english–german cross-lingual summarization settings demonstrate the effectiveness of our methods. in addition , we find that reinforcement learning models with bilingual semantic similarity as rewards generate more fluent sentences than strong baselines.
