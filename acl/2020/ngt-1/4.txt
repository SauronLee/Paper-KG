Meta-Learning for Few-Shot NMT Adaptation | Amr Sharaf | we present meta-mt , a meta-learning approach to adapt neural machine translation \( nmt \) systems in a few-shot setting. meta-mt provides a new approach to make nmt models easily adaptable to many target do- mains with the minimal amount of in-domain data. we frame the adaptation of nmt systems as a meta-learning problem , where we learn to adapt to new unseen domains based on simulated offline meta-training domain adaptation tasks. we evaluate the proposed meta-learning strategy on ten domains with general large scale nmt systems. we show that meta-mt significantly outperforms classical domain adaptation when very few in- domain examples are available. our experiments shows that meta-mt can outperform classical fine-tuning by up to 2.5 bleu points after seeing only 4 , 000 translated words \( 300 parallel sentences \) .
