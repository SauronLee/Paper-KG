Efficient and High-Quality Neural Machine Translation with OpenNMT | Guillaume Klein | this paper describes the opennmt submissions to the wngt 2020 efficiency shared task. we explore training and acceleration of transformer models with various sizes that are trained in a teacher-student setup. we also present a custom and optimized c++ inference engine that enables fast cpu and gpu decoding with few dependencies. by combining additional optimizations and parallelization techniques , we create small , efficient , and high-quality neural machine translation models.
