Re-translation versus Streaming for Simultaneous Translation | Naveen Arivazhagan | there has been great progress in improving streaming machine translation , a simultaneous paradigm where the system appends to a growing hypothesis as more source content becomes available. we study a related problem in which revisions to the hypothesis beyond strictly appending words are permitted. this is suitable for applications such as live captioning an audio feed. in this setting , we compare custom streaming approaches to re-translation , a straightforward strategy where each new source token triggers a distinct translation from scratch. we find re-translation to be as good or better than state-of-the-art streaming systems , even when operating under constraints that allow very few revisions. we attribute much of this success to a previously proposed data-augmentation technique that adds prefix-pairs to the training data , which alongside wait-k inference forms a strong baseline for streaming translation. we also highlight re-translationâ€™s ability to wrap arbitrarily powerful mt systems with an experiment showing large improvements from an upgrade to its base model.
