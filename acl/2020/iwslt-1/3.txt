KIT’s IWSLT 2020 SLT Translation System | Ngoc-Quan Pham | this paper describes kit’s submissions to the iwslt2020 speech translation evaluation campaign. we first participate in the simultaneous translation task , in which our simultaneous models are transformer based and can be efficiently trained to obtain low latency with minimized compromise in quality. on the offline speech translation task , we applied our new speech transformer architecture to end-to-end speech translation. the obtained model can provide translation quality which is competitive to a complicated cascade. the latter still has the upper hand , thanks to the ability to transparently access to the transcription , and resegment the inputs to avoid fragmentation.
