Adapting End-to-End Speech Recognition for Readable Subtitles | Danni Liu | automatic speech recognition \( asr \) systems are primarily evaluated on transcription accuracy. however , in some use cases such as subtitling , verbatim transcription would reduce output readability given limited screen size and reading time. therefore , this work focuses on asr with output compression , a task challenging for supervised approaches due to the scarcity of training data. we first investigate a cascaded system , where an unsupervised compression model is used to post-edit the transcribed speech. we then compare several methods of end-to-end speech recognition under output length constraints. the experiments show that with limited data far less than needed for training a model from scratch , we can adapt a transformer-based asr model to incorporate both transcription and compression capabilities. furthermore , the best performance in terms of wer and rouge scores is achieved by explicitly modeling the length constraints within the end-to-end asr system.
