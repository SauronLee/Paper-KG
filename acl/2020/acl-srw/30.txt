Preventing Critical Scoring Errors in Short Answer Scoring with Confidence Estimation | Hiroaki Funayama | user generated texts contain many typos for which correction is necessary for nlp systems to work. although a large number of typo–correction pairs are needed to develop a data-driven typo correction system , no such dataset is available for japanese. in this paper , we extract over half a million japanese typo–correction pairs from wikipedia’s revision history. unlike other languages , japanese poses unique challenges: \( 1 \) japanese texts are unsegmented so that we cannot simply apply a spelling checker , and \( 2 \) the way people inputting kanji logographs results in typos with drastically different surface forms from correct ones. we address them by combining character-based extraction rules , morphological analyzers to guess readings , and various filtering methods. we evaluate the dataset using crowdsourcing and run a baseline seq2seq model for typo correction.
