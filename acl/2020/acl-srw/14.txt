Multi-Task Neural Model for Agglutinative Language Translation | Yirong Pan | neural machine translation \( nmt \) has achieved impressive performance recently by using large-scale parallel corpora. however , it struggles in the low-resource and morphologically-rich scenarios of agglutinative language translation task. inspired by the finding that monolingual data can greatly improve the nmt performance , we propose a multi-task neural model that jointly learns to perform bi-directional translation and agglutinative language stemming. our approach employs the shared encoder and decoder to train a single model without changing the standard nmt architecture but instead adding a token before each source-side sentence to specify the desired target outputs of the two different tasks. experimental results on turkish-english and uyghur-chinese show that our proposed approach can significantly improve the translation performance on agglutinative languages by using a small amount of monolingual data.
