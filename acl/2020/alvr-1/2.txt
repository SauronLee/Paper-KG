Visual Question Generation from Radiology Images | Mourad Sarrouti | visual question generation \( vqg \) , the task of generating a question based on image contents , is an increasingly important area that combines natural language processing and computer vision. although there are some recent works that have attempted to generate questions from images in the open domain , the task of vqg in the medical domain has not been explored so far. in this paper , we introduce an approach to generation of visual questions about radiology images called vqgr , i.e. an algorithm that is able to ask a question when shown an image. vqgr first generates new training data from the existing examples , based on contextual word embeddings and image augmentation techniques. it then uses the variational auto-encoders model to encode images into a latent space and decode natural language questions. experimental automatic evaluations performed on the vqa-rad dataset of clinical visual questions show that vqgr achieves good performances compared with the baseline system. the source code is available at https://github.com/sarrouti/vqgr.
